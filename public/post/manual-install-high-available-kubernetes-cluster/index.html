<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    <meta property="og:site_name" content="青年夏日IT">
    <meta property="og:type" content="article">

    
    <meta property="og:image" content="https://qnxr.xyz/img/home-bg-jeep.jpg">
    <meta property="twitter:image" content="https://qnxr.xyz/img/home-bg-jeep.jpg" />
    

    
    <meta name="title" content="手动搭建高可用的kubernetes 集群" />
    <meta property="og:title" content="手动搭建高可用的kubernetes 集群" />
    <meta property="twitter:title" content="手动搭建高可用的kubernetes 集群" />
    

    
    <meta name="description" content="青年夏日，程序员, 开源爱好者，生活探险家 | 这里是 青年夏日 的博客，与你一起发现更大的世界。">
    <meta property="og:description" content="青年夏日，程序员, 开源爱好者，生活探险家 | 这里是 青年夏日 的博客，与你一起发现更大的世界。" />
    <meta property="twitter:description" content="青年夏日，程序员, 开源爱好者，生活探险家 | 这里是 青年夏日 的博客，与你一起发现更大的世界。" />
    

    
    <meta property="twitter:card" content="summary" />
    
    

    <meta name="keyword"  content="青年夏日, 博客, 个人网站, 互联网, Web, 云原生, PaaS, Istio, Kubernetes, 微服务, Microservice">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>手动搭建高可用的kubernetes 集群-青年夏日IT</title>

    <link rel="canonical" href="/post/manual-install-high-available-kubernetes-cluster/">

    <link rel="stylesheet" href="/css/iDisqus.min.css"/>

    
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    
    <link rel="stylesheet" href="/css/hux-blog.min.css">

    
    <link rel="stylesheet" href="/css/zanshang.css">

    
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css" rel="stylesheet" type="text/css">

    
    

    
    
    <script src="/js/jquery.min.js"></script>

    
    <script src="/js/bootstrap.min.js"></script>

    
    <script src="/js/hux-blog.min.js"></script>

    
    

</head>



<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">青年夏日IT</a>
        </div>

        
        
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
                    
                        
                        <li>
                            <a href="/categories/life">life</a>
                        </li>
                        
                        <li>
                            <a href="/categories/note">note</a>
                        </li>
                        
                        <li>
                            <a href="/categories/tech">tech</a>
                        </li>
                        
                        <li>
                            <a href="/categories/tips">tips</a>
                        </li>
                        
                    
                    
		    
                        <li><a href="/top/books/">BOOKS</a></li>
                    
                        <li><a href="/top/about/">ABOUT</a></li>
                    

                    
		    <li>
                        <a href="/search">SEARCH <img src="/img/search.png" height="15" style="cursor: pointer;" alt="Search"></a>
		    </li>
                    
                </ul>
            </div>
        </div>
        
    </div>
    
</nav>
<script>
    
    
    
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        
            $navbar.className = " ";
            
            setTimeout(function(){
                
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>




<style type="text/css">
    header.intro-header {
        background-image: url('/img/home-bg-jeep.jpg')
    }
</style>
<header class="intro-header">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/kubernetes" title="kubernetes">
                            kubernetes
                        </a>
                        
                        <a class="tag" href="/tags/%E9%AB%98%E5%8F%AF%E7%94%A8" title="高可用">
                            高可用
                        </a>
                        
                        <a class="tag" href="/tags/%E9%9B%86%E7%BE%A4" title="集群">
                            集群
                        </a>
                        
                        <a class="tag" href="/tags/docker" title="docker">
                            docker
                        </a>
                        
                    </div>
                    <h1>手动搭建高可用的kubernetes 集群</h1>
                    <h2 class="subheading"></h2>
                    <span class="meta">
                        Posted by 
                        
                                青年夏日IT
                         
                        on 
                        Monday, November 6, 2017
                        
                        
                        
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>




<article>
    <div class="container">
        <div class="row">

            
            <div class="
                col-lg-11 col-lg-offset-1
                col-md-10 col-md-offset-1
                post-container">

                
                <header>
                    <h2>TOC</h2>
                </header>
                <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#1-组件版本--集群环境a-idinit-enva">1. 组件版本 &amp;&amp; 集群环境<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
        <li><a href="#2-创建ca-证书和密钥a-idcreate-caa">2. 创建CA 证书和密钥<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
        <li><a href="#3-部署高可用etcd-集群a-idetcda">3. 部署高可用etcd 集群<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
        <li><a href="#4-配置kubectl-命令行工具a-idkubectla">4. 配置kubectl 命令行工具<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
        <li><a href="#5-部署flannel-网络a-idflannelda">5. 部署Flannel 网络<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
        <li><a href="#6-部署master-节点a-idmastera">6. 部署master 节点<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
        <li><a href="#7-kube-apiserver-高可用a-idhaa">7. kube-apiserver 高可用<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
        <li><a href="#8-部署node-节点a-idnodea">8. 部署Node 节点<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
        <li><a href="#9-部署kubedns-插件a-idkubednsa">9. 部署kubedns 插件<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
        <li><a href="#10-部署dashboard-插件a-iddashboarda">10. 部署Dashboard 插件<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
        <li><a href="#11-部署heapster-插件a-idheapstera">11. 部署Heapster 插件<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
        <li><a href="#12-安装ingressa-idingressa">12. 安装Ingress<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
        <li><a href="#13-日志收集a-idlog-collecta">13. 日志收集<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
        <li><a href="#14-私有仓库harbor-搭建a-idharbora">14. 私有仓库harbor 搭建<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
        <li><a href="#15-问题汇总a-idquestiona">15. 问题汇总<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
        <li><a href="#参考资料a-idlinka">参考资料<!-- raw HTML omitted --><!-- raw HTML omitted --></a></li>
      </ul>
    </li>
  </ul>
</nav>
                
                <p>之前按照<a href="https://github.com/opsnull/follow-me-install-kubernetes-cluster">和我一步步部署 kubernetes 集群</a>的步骤一步一步的成功的使用二进制的方式安装了<code>kubernetes</code>集群，在该文档的基础上重新部署了最新的<code>v1.8.2</code>版本，实现了<code>kube-apiserver</code>的高可用、<code>traefik ingress</code> 的部署、在<code>kubernetes</code>上安装<code>docker</code>的私有仓库<code>harbor</code>、容器化<code>kubernetes</code>部分组建、使用阿里云日志服务收集日志。</p>
<p>部署完成后，你将理解系统各组件的交互原理，进而能快速解决实际问题，所以本文档主要适合于那些有一定<code>kubernetes</code>基础，想通过一步步部署的方式来学习和了解系统配置、运行原理的人。</p>
<p>本系列系文档适用于 <code>CentOS 7</code>、<code>Ubuntu 16.04</code> 及以上版本系统，由于启用了 <code>TLS</code> 双向认证、<code>RBAC</code> 授权等严格的安全机制，建议<strong>从头开始部署</strong>，否则可能会认证、授权等失败！</p>
<blockquote>
<p>有人问我为什么这么长的文章不分拆成几篇文章啊？这样阅读起来也方便啊，然而在我自己学习的过程中，这种整个一篇文章把一件事情从头到尾讲清楚的形式是最好的，能给读者提供一种<code>沉浸式</code>的学习体验，阅读完整个文章后有种<code>酣畅淋漓</code>的感觉，所以我选择这种一篇文章的形式。</p>
</blockquote>
<p>另外我录制了<a href="https://www.haimaxy.com/course/pjrqxm/?utm_source=blog">基于1.9版本手动搭建高可用Kubernetes集群的视频教程</a>，对视频感兴趣的同学可以观看视频：​
<a href="https://www.haimaxy.com/course/pjrqxm/?utm_source=blog">
  <img src="/img/posts/k8s-install-pay-course.jpeg" alt="视频教程">

</a></p>
<p>扫描下面的二维码(或微信搜索<code>k8s技术圈</code>)关注我们的微信公众帐号，在微信公众帐号中回复 <strong>加群</strong> 即可加入到我们的 kubernetes 讨论群里面共同学习。

  <img src="/img/posts/qrcode_for_gh_d6dd87b6ceb4_430.jpg" alt="qrcode">

</p>
<h2 id="1-组件版本--集群环境a-idinit-enva">1. 组件版本 &amp;&amp; 集群环境<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<h3 id="组件版本">组件版本</h3>
<ul>
<li>Kubernetes 1.8.2(1.9.x版本也可以，只有细微的差别)</li>
<li>Docker 17.10.0-ce</li>
<li>Etcd 3.2.9</li>
<li>Flanneld</li>
<li>TLS 认证通信（所有组件，如etcd、kubernetes master 和node）</li>
<li>RBAC 授权</li>
<li>kubelet TLS Bootstrapping</li>
<li>kubedns、dashboard、heapster等插件</li>
<li>harbor，使用nfs后端存储</li>
</ul>
<h3 id="etcd-集群--k8s-master-机器--k8s-node-机器">etcd 集群 &amp;&amp; k8s master 机器 &amp;&amp; k8s node 机器</h3>
<ul>
<li>master01：192.168.1.137</li>
<li>master02：192.168.1.138</li>
<li>master03/node03：192.168.1.170</li>
<li>由于机器有限，所以我们将master03 也作为node 节点，后续有新的机器增加即可</li>
<li>node01: 192.168.1.161</li>
<li>node02: 192.168.1.162</li>
</ul>
<h3 id="集群环境变量">集群环境变量</h3>
<p>后面的嗯部署将会使用到的全局变量，定义如下（根据自己的机器、网络修改）：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#6272a4"># TLS Bootstrapping 使用的Token，可以使用命令 head -c 16 /dev/urandom | od -An -t x | tr -d &#39; &#39; 生成</span>
<span style="color:#8be9fd;font-style:italic">BOOTSTRAP_TOKEN</span><span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;8981b594122ebed7596f1d3b69c78223&#34;</span>

<span style="color:#6272a4"># 建议使用未用的网段来定义服务网段和Pod 网段</span>
<span style="color:#6272a4"># 服务网段(Service CIDR)，部署前路由不可达，部署后集群内部使用IP:Port可达</span>
<span style="color:#8be9fd;font-style:italic">SERVICE_CIDR</span><span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;10.254.0.0/16&#34;</span>
<span style="color:#6272a4"># Pod 网段(Cluster CIDR)，部署前路由不可达，部署后路由可达(flanneld 保证)</span>
<span style="color:#8be9fd;font-style:italic">CLUSTER_CIDR</span><span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;172.30.0.0/16&#34;</span>

<span style="color:#6272a4"># 服务端口范围(NodePort Range)</span>
<span style="color:#8be9fd;font-style:italic">NODE_PORT_RANGE</span><span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;30000-32766&#34;</span>

<span style="color:#6272a4"># etcd集群服务地址列表</span>
<span style="color:#8be9fd;font-style:italic">ETCD_ENDPOINTS</span><span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;https://192.168.1.137:2379,https://192.168.1.138:2379,https://192.168.1.170:2379&#34;</span>

<span style="color:#6272a4"># flanneld 网络配置前缀</span>
<span style="color:#8be9fd;font-style:italic">FLANNEL_ETCD_PREFIX</span><span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;/kubernetes/network&#34;</span>

<span style="color:#6272a4"># kubernetes 服务IP(预先分配，一般为SERVICE_CIDR中的第一个IP)</span>
<span style="color:#8be9fd;font-style:italic">CLUSTER_KUBERNETES_SVC_IP</span><span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;10.254.0.1&#34;</span>

<span style="color:#6272a4"># 集群 DNS 服务IP(从SERVICE_CIDR 中预先分配)</span>
<span style="color:#8be9fd;font-style:italic">CLUSTER_DNS_SVC_IP</span><span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;10.254.0.2&#34;</span>

<span style="color:#6272a4"># 集群 DNS 域名</span>
<span style="color:#8be9fd;font-style:italic">CLUSTER_DNS_DOMAIN</span><span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;cluster.local.&#34;</span>

<span style="color:#6272a4"># MASTER API Server 地址</span>
<span style="color:#8be9fd;font-style:italic">MASTER_URL</span><span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;k8s-api.virtual.local&#34;</span>
</code></pre></div><p>将上面变量保存为: <strong>env.sh</strong>，然后将脚本拷贝到所有机器的<code>/usr/k8s/bin</code>目录。</p>
<!-- raw HTML omitted -->
<p>为方便后面迁移，我们在集群内定义一个域名用于访问<code>apiserver</code>，在每个节点的<code>/etc/hosts</code>文件中添加记录：<strong>192.168.1.137 k8s-api.virtual.local k8s-api</strong></p>
<p>其中<code>192.168.1.137</code>为master01 的IP，暂时使用该IP 来做apiserver 的负载地址</p>
<blockquote>
<p>如果你使用的是阿里云的ECS 服务，强烈建议你先将上述节点的安全组配置成允许所有访问，不然在安装过程中会遇到各种访问不了的问题，待集群配置成功以后再根据需要添加安全限制。</p>
</blockquote>
<h2 id="2-创建ca-证书和密钥a-idcreate-caa">2. 创建CA 证书和密钥<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<p><code>kubernetes</code> 系统各个组件需要使用<code>TLS</code>证书对通信进行加密，这里我们使用<code>CloudFlare</code>的PKI 工具集<a href="https://github.com/cloudflare/cfssl">cfssl</a> 来生成Certificate Authority(CA) 证书和密钥文件， CA 是自签名的证书，用来签名后续创建的其他TLS 证书。</p>
<h3 id="安装-cfssl">安装 CFSSL</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64
$ chmod +x cfssl_linux-amd64
$ sudo mv cfssl_linux-amd64 /usr/k8s/bin/cfssl

$ wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64
$ chmod +x cfssljson_linux-amd64
$ sudo mv cfssljson_linux-amd64 /usr/k8s/bin/cfssljson

$ wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64
$ chmod +x cfssl-certinfo_linux-amd64
$ sudo mv cfssl-certinfo_linux-amd64 /usr/k8s/bin/cfssl-certinfo

$ <span style="color:#8be9fd;font-style:italic">export</span> <span style="color:#8be9fd;font-style:italic">PATH</span><span style="color:#ff79c6">=</span>/usr/k8s/bin:<span style="color:#8be9fd;font-style:italic">$PATH</span>
$ mkdir ssl <span style="color:#ff79c6">&amp;&amp;</span> <span style="color:#8be9fd;font-style:italic">cd</span> ssl
$ cfssl print-defaults config &gt; config.json
$ cfssl print-defaults csr &gt; csr.json
</code></pre></div><p>为了方便，将<code>/usr/k8s/bin</code>设置成环境变量，为了重启也有效，可以将上面的<code>export PATH=/usr/k8s/bin:$PATH</code>添加到<code>/etc/rc.local</code>文件中。</p>
<h3 id="创建ca">创建CA</h3>
<p>修改上面创建的<code>config.json</code>文件为<code>ca-config.json</code>：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat ca-config.json
<span style="color:#ff79c6">{</span>
    <span style="color:#f1fa8c">&#34;signing&#34;</span>: <span style="color:#ff79c6">{</span>
        <span style="color:#f1fa8c">&#34;default&#34;</span>: <span style="color:#ff79c6">{</span>
            <span style="color:#f1fa8c">&#34;expiry&#34;</span>: <span style="color:#f1fa8c">&#34;87600h&#34;</span>
        <span style="color:#ff79c6">}</span>,
        <span style="color:#f1fa8c">&#34;profiles&#34;</span>: <span style="color:#ff79c6">{</span>
            <span style="color:#f1fa8c">&#34;kubernetes&#34;</span>: <span style="color:#ff79c6">{</span>
                <span style="color:#f1fa8c">&#34;expiry&#34;</span>: <span style="color:#f1fa8c">&#34;87600h&#34;</span>,
                <span style="color:#f1fa8c">&#34;usages&#34;</span>: <span style="color:#ff79c6">[</span>
                    <span style="color:#f1fa8c">&#34;signing&#34;</span>,
                    <span style="color:#f1fa8c">&#34;key encipherment&#34;</span>,
                    <span style="color:#f1fa8c">&#34;server auth&#34;</span>,
                    <span style="color:#f1fa8c">&#34;client auth&#34;</span>
                <span style="color:#ff79c6">]</span>
            <span style="color:#ff79c6">}</span>
        <span style="color:#ff79c6">}</span>
    <span style="color:#ff79c6">}</span>
<span style="color:#ff79c6">}</span>
</code></pre></div><ul>
<li><code>config.json</code>：可以定义多个profiles，分别指定不同的过期时间、使用场景等参数；后续在签名证书时使用某个profile；</li>
<li><code>signing</code>: 表示该证书可用于签名其它证书；生成的ca.pem 证书中<code>CA=TRUE</code>；</li>
<li><code>server auth</code>: 表示client 可以用该CA 对server 提供的证书进行校验；</li>
<li><code>client auth</code>: 表示server 可以用该CA 对client 提供的证书进行验证。</li>
</ul>
<p>修改CA 证书签名请求为<code>ca-csr.json</code>：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat ca-csr.json
<span style="color:#ff79c6">{</span>
    <span style="color:#f1fa8c">&#34;CN&#34;</span>: <span style="color:#f1fa8c">&#34;kubernetes&#34;</span>,
    <span style="color:#f1fa8c">&#34;key&#34;</span>: <span style="color:#ff79c6">{</span>
        <span style="color:#f1fa8c">&#34;algo&#34;</span>: <span style="color:#f1fa8c">&#34;rsa&#34;</span>,
        <span style="color:#f1fa8c">&#34;size&#34;</span>: <span style="color:#bd93f9">2048</span>
    <span style="color:#ff79c6">}</span>,
    <span style="color:#f1fa8c">&#34;names&#34;</span>: <span style="color:#ff79c6">[</span>
        <span style="color:#ff79c6">{</span>
            <span style="color:#f1fa8c">&#34;C&#34;</span>: <span style="color:#f1fa8c">&#34;CN&#34;</span>,
            <span style="color:#f1fa8c">&#34;L&#34;</span>: <span style="color:#f1fa8c">&#34;BeiJing&#34;</span>,
            <span style="color:#f1fa8c">&#34;ST&#34;</span>: <span style="color:#f1fa8c">&#34;BeiJing&#34;</span>,
            <span style="color:#f1fa8c">&#34;O&#34;</span>: <span style="color:#f1fa8c">&#34;k8s&#34;</span>,
            <span style="color:#f1fa8c">&#34;OU&#34;</span>: <span style="color:#f1fa8c">&#34;System&#34;</span>
        <span style="color:#ff79c6">}</span>
    <span style="color:#ff79c6">]</span>
<span style="color:#ff79c6">}</span>
</code></pre></div><ul>
<li><code>CN</code>: <code>Common Name</code>，kube-apiserver 从证书中提取该字段作为请求的用户名(User Name)；浏览器使用该字段验证网站是否合法；</li>
<li><code>O</code>: <code>Organization</code>，kube-apiserver 从证书中提取该字段作为请求用户所属的组(Group)；</li>
</ul>
<p>生成CA 证书和私钥：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cfssl gencert -initca ca-csr.json | cfssljson -bare ca
$ ls ca*
$ ca-config.json  ca.csr  ca-csr.json  ca-key.pem  ca.pem
</code></pre></div><h3 id="分发证书">分发证书</h3>
<p>将生成的CA 证书、密钥文件、配置文件拷贝到所有机器的<code>/etc/kubernetes/ssl</code>目录下面：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo mkdir -p /etc/kubernetes/ssl
$ sudo cp ca* /etc/kubernetes/ssl
</code></pre></div><h2 id="3-部署高可用etcd-集群a-idetcda">3. 部署高可用etcd 集群<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<p>kubernetes 系统使用<code>etcd</code>存储所有的数据，我们这里部署3个节点的etcd 集群，这3个节点直接复用kubernetes master的3个节点，分别命名为<code>etcd01</code>、<code>etcd02</code>、<code>etcd03</code>:</p>
<ul>
<li>etcd01：192.168.1.137</li>
<li>etcd02：192.168.1.138</li>
<li>etcd03：192.168.1.170</li>
</ul>
<h3 id="定义环境变量">定义环境变量</h3>
<p>使用到的变量如下：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ <span style="color:#8be9fd;font-style:italic">export</span> <span style="color:#8be9fd;font-style:italic">NODE_NAME</span><span style="color:#ff79c6">=</span>etcd01 <span style="color:#6272a4"># 当前部署的机器名称(随便定义，只要能区分不同机器即可)</span>
$ <span style="color:#8be9fd;font-style:italic">export</span> <span style="color:#8be9fd;font-style:italic">NODE_IP</span><span style="color:#ff79c6">=</span>192.168.1.137 <span style="color:#6272a4"># 当前部署的机器IP</span>
$ <span style="color:#8be9fd;font-style:italic">export</span> <span style="color:#8be9fd;font-style:italic">NODE_IPS</span><span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;192.168.1.137 192.168.1.138 192.168.1.170&#34;</span> <span style="color:#6272a4"># etcd 集群所有机器 IP</span>
$ <span style="color:#6272a4"># etcd 集群间通信的IP和端口</span>
$ <span style="color:#8be9fd;font-style:italic">export</span> <span style="color:#8be9fd;font-style:italic">ETCD_NODES</span><span style="color:#ff79c6">=</span><span style="color:#8be9fd;font-style:italic">etcd01</span><span style="color:#ff79c6">=</span>https://192.168.1.137:2380,etcd02<span style="color:#ff79c6">=</span>https://192.168.1.138:2380,etcd03<span style="color:#ff79c6">=</span>https://192.168.1.170:2380
$ <span style="color:#6272a4"># 导入用到的其它全局变量：ETCD_ENDPOINTS、FLANNEL_ETCD_PREFIX、CLUSTER_CIDR</span>
$ <span style="color:#8be9fd;font-style:italic">source</span> /usr/k8s/bin/env.sh
</code></pre></div><h3 id="下载etcd-二进制文件">下载etcd 二进制文件</h3>
<p>到<a href="https://github.com/coreos/etcd/releases">https://github.com/coreos/etcd/releases</a>页面下载最新版本的二进制文件：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ wget https://github.com/coreos/etcd/releases/download/v3.2.9/etcd-v3.2.9-linux-amd64.tar.gz
$ tar -xvf etcd-v3.2.9-linux-amd64.tar.gz
$ sudo mv etcd-v3.2.9-linux-amd64/etcd* /usr/k8s/bin/
</code></pre></div><h3 id="创建tls-密钥和证书">创建TLS 密钥和证书</h3>
<p>为了保证通信安全，客户端(如etcdctl)与etcd 集群、etcd 集群之间的通信需要使用TLS 加密。</p>
<p>创建etcd 证书签名请求：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat &gt; etcd-csr.json <span style="color:#f1fa8c">&lt;&lt;EOF
</span><span style="color:#f1fa8c">{
</span><span style="color:#f1fa8c">  &#34;CN&#34;: &#34;etcd&#34;,
</span><span style="color:#f1fa8c">  &#34;hosts&#34;: [
</span><span style="color:#f1fa8c">    &#34;127.0.0.1&#34;,
</span><span style="color:#f1fa8c">    &#34;${NODE_IP}&#34;
</span><span style="color:#f1fa8c">  ],
</span><span style="color:#f1fa8c">  &#34;key&#34;: {
</span><span style="color:#f1fa8c">    &#34;algo&#34;: &#34;rsa&#34;,
</span><span style="color:#f1fa8c">    &#34;size&#34;: 2048
</span><span style="color:#f1fa8c">  },
</span><span style="color:#f1fa8c">  &#34;names&#34;: [
</span><span style="color:#f1fa8c">    {
</span><span style="color:#f1fa8c">      &#34;C&#34;: &#34;CN&#34;,
</span><span style="color:#f1fa8c">      &#34;ST&#34;: &#34;BeiJing&#34;,
</span><span style="color:#f1fa8c">      &#34;L&#34;: &#34;BeiJing&#34;,
</span><span style="color:#f1fa8c">      &#34;O&#34;: &#34;k8s&#34;,
</span><span style="color:#f1fa8c">      &#34;OU&#34;: &#34;System&#34;
</span><span style="color:#f1fa8c">    }
</span><span style="color:#f1fa8c">  ]
</span><span style="color:#f1fa8c">}
</span><span style="color:#f1fa8c">EOF</span>
</code></pre></div><ul>
<li><code>hosts</code> 字段指定授权使用该证书的<code>etcd</code>节点IP</li>
</ul>
<p>生成<code>etcd</code>证书和私钥：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cfssl gencert -ca<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  -ca-key<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca-key.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  -config<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca-config.json <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  -profile<span style="color:#ff79c6">=</span>kubernetes etcd-csr.json | cfssljson -bare etcd
$ ls etcd*
etcd.csr  etcd-csr.json  etcd-key.pem  etcd.pem
$ sudo mkdir -p /etc/etcd/ssl
$ sudo mv etcd*.pem /etc/etcd/ssl/
</code></pre></div><h3 id="创建etcd-的systemd-unit-文件">创建etcd 的systemd unit 文件</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo mkdir -p /var/lib/etcd  <span style="color:#6272a4"># 必须要先创建工作目录</span>
$ cat &gt; etcd.service <span style="color:#f1fa8c">&lt;&lt;EOF
</span><span style="color:#f1fa8c">[Unit]
</span><span style="color:#f1fa8c">Description=Etcd Server
</span><span style="color:#f1fa8c">After=network.target
</span><span style="color:#f1fa8c">After=network-online.target
</span><span style="color:#f1fa8c">Wants=network-online.target
</span><span style="color:#f1fa8c">Documentation=https://github.com/coreos
</span><span style="color:#f1fa8c">
</span><span style="color:#f1fa8c">[Service]
</span><span style="color:#f1fa8c">Type=notify
</span><span style="color:#f1fa8c">WorkingDirectory=/var/lib/etcd/
</span><span style="color:#f1fa8c">ExecStart=/usr/k8s/bin/etcd \\
</span><span style="color:#f1fa8c">  --name=${NODE_NAME} \\
</span><span style="color:#f1fa8c">  --cert-file=/etc/etcd/ssl/etcd.pem \\
</span><span style="color:#f1fa8c">  --key-file=/etc/etcd/ssl/etcd-key.pem \\
</span><span style="color:#f1fa8c">  --peer-cert-file=/etc/etcd/ssl/etcd.pem \\
</span><span style="color:#f1fa8c">  --peer-key-file=/etc/etcd/ssl/etcd-key.pem \\
</span><span style="color:#f1fa8c">  --trusted-ca-file=/etc/kubernetes/ssl/ca.pem \\
</span><span style="color:#f1fa8c">  --peer-trusted-ca-file=/etc/kubernetes/ssl/ca.pem \\
</span><span style="color:#f1fa8c">  --initial-advertise-peer-urls=https://${NODE_IP}:2380 \\
</span><span style="color:#f1fa8c">  --listen-peer-urls=https://${NODE_IP}:2380 \\
</span><span style="color:#f1fa8c">  --listen-client-urls=https://${NODE_IP}:2379,http://127.0.0.1:2379 \\
</span><span style="color:#f1fa8c">  --advertise-client-urls=https://${NODE_IP}:2379 \\
</span><span style="color:#f1fa8c">  --initial-cluster-token=etcd-cluster-0 \\
</span><span style="color:#f1fa8c">  --initial-cluster=${ETCD_NODES} \\
</span><span style="color:#f1fa8c">  --initial-cluster-state=new \\
</span><span style="color:#f1fa8c">  --data-dir=/var/lib/etcd
</span><span style="color:#f1fa8c">Restart=on-failure
</span><span style="color:#f1fa8c">RestartSec=5
</span><span style="color:#f1fa8c">LimitNOFILE=65536
</span><span style="color:#f1fa8c">
</span><span style="color:#f1fa8c">[Install]
</span><span style="color:#f1fa8c">WantedBy=multi-user.target
</span><span style="color:#f1fa8c">EOF</span>
</code></pre></div><ul>
<li>指定<code>etcd</code>的工作目录和数据目录为<code>/var/lib/etcd</code>，需要在启动服务前创建这个目录；</li>
<li>为了保证通信安全，需要指定etcd 的公私钥(cert-file和key-file)、Peers通信的公私钥和CA 证书(peer-cert-file、peer-key-file、peer-trusted-ca-file)、客户端的CA 证书(trusted-ca-file)；</li>
<li><code>--initial-cluster-state</code>值为<code>new</code>时，<code>--name</code>的参数值必须位于<code>--initial-cluster</code>列表中；</li>
</ul>
<h3 id="启动etcd-服务">启动etcd 服务</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo mv etcd.service /etc/systemd/system/
$ sudo systemctl daemon-reload
$ sudo systemctl <span style="color:#8be9fd;font-style:italic">enable</span> etcd
$ sudo systemctl start etcd
$ sudo systemctl status etcd
</code></pre></div><p>最先启动的etcd 进程会卡住一段时间，等待其他节点启动加入集群，在所有的etcd 节点重复上面的步骤，直到所有的机器etcd 服务都已经启动。</p>
<!-- raw HTML omitted -->
<h3 id="验证服务">验证服务</h3>
<p>部署完etcd 集群后，在任一etcd 节点上执行下面命令：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#ff79c6">for</span> ip in <span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">NODE_IPS</span><span style="color:#f1fa8c">}</span>; <span style="color:#ff79c6">do</span>
  <span style="color:#8be9fd;font-style:italic">ETCDCTL_API</span><span style="color:#ff79c6">=</span><span style="color:#bd93f9">3</span> /usr/k8s/bin/etcdctl <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --endpoints<span style="color:#ff79c6">=</span>https://<span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">ip</span><span style="color:#f1fa8c">}</span>:2379  <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --cacert<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --cert<span style="color:#ff79c6">=</span>/etc/etcd/ssl/etcd.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --key<span style="color:#ff79c6">=</span>/etc/etcd/ssl/etcd-key.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  endpoint health; <span style="color:#ff79c6">done</span>
</code></pre></div><p>输出如下结果：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">https://192.168.1.137:2379 is healthy: successfully committed proposal: <span style="color:#8be9fd;font-style:italic">took</span> <span style="color:#ff79c6">=</span> 1.509032ms
https://192.168.1.138:2379 is healthy: successfully committed proposal: <span style="color:#8be9fd;font-style:italic">took</span> <span style="color:#ff79c6">=</span> 1.639228ms
https://192.168.1.170:2379 is healthy: successfully committed proposal: <span style="color:#8be9fd;font-style:italic">took</span> <span style="color:#ff79c6">=</span> 1.4152ms
</code></pre></div><p>可以看到上面的信息3个节点上的etcd 均为<strong>healthy</strong>，则表示集群服务正常。</p>
<h2 id="4-配置kubectl-命令行工具a-idkubectla">4. 配置kubectl 命令行工具<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<p><code>kubectl</code>默认从<code>~/.kube/config</code>配置文件中获取访问kube-apiserver 地址、证书、用户名等信息，需要正确配置该文件才能正常使用<code>kubectl</code>命令。</p>
<p>需要将下载的kubectl 二进制文件和生产的<code>~/.kube/config</code>配置文件拷贝到需要使用kubectl 命令的机器上。</p>
<blockquote>
<p>很多童鞋说这个地方不知道在哪个节点上执行，<code>kubectl</code>只是一个和<code>kube-apiserver</code>进行交互的一个命令行工具，所以你想安装到那个节点都行，master或者node任意节点都可以，比如你先在master节点上安装，这样你就可以在master节点使用<code>kubectl</code>命令行工具了，如果你想在node节点上使用(当然安装的过程肯定会用到的)，你就把master上面的<code>kubectl</code>二进制文件和<code>~/.kube/config</code>文件拷贝到对应的node节点上就行了。</p>
</blockquote>
<h3 id="环境变量">环境变量</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ <span style="color:#8be9fd;font-style:italic">source</span> /usr/k8s/bin/env.sh
$ <span style="color:#8be9fd;font-style:italic">export</span> <span style="color:#8be9fd;font-style:italic">KUBE_APISERVER</span><span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;https://</span><span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">MASTER_URL</span><span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">:6443&#34;</span>
</code></pre></div><blockquote>
<p>注意这里的<code>KUBE_APISERVER</code>地址，因为我们还没有安装<code>haproxy</code>，所以暂时需要手动指定使用<code>apiserver</code>的6443端口，等<code>haproxy</code>安装完成后就可以用使用443端口转发到6443端口去了。</p>
</blockquote>
<ul>
<li>变量KUBE_APISERVER 指定kubelet 访问的kube-apiserver 的地址，后续被写入<code>~/.kube/config</code>配置文件</li>
</ul>
<h3 id="下载kubectl">下载kubectl</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ wget https://dl.k8s.io/v1.8.2/kubernetes-client-linux-amd64.tar.gz <span style="color:#6272a4"># 如果服务器上下载不下来，可以想办法下载到本地，然后scp上去即可</span>
$ tar -xzvf kubernetes-client-linux-amd64.tar.gz
$ sudo cp kubernetes/client/bin/kube* /usr/k8s/bin/
$ sudo chmod a+x /usr/k8s/bin/kube*
$ <span style="color:#8be9fd;font-style:italic">export</span> <span style="color:#8be9fd;font-style:italic">PATH</span><span style="color:#ff79c6">=</span>/usr/k8s/bin:<span style="color:#8be9fd;font-style:italic">$PATH</span>
</code></pre></div><h3 id="创建admin-证书">创建admin 证书</h3>
<p>kubectl 与kube-apiserver 的安全端口通信，需要为安全通信提供TLS 证书和密钥。创建admin 证书签名请求：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat &gt; admin-csr.json <span style="color:#f1fa8c">&lt;&lt;EOF
</span><span style="color:#f1fa8c">{
</span><span style="color:#f1fa8c">  &#34;CN&#34;: &#34;admin&#34;,
</span><span style="color:#f1fa8c">  &#34;hosts&#34;: [],
</span><span style="color:#f1fa8c">  &#34;key&#34;: {
</span><span style="color:#f1fa8c">    &#34;algo&#34;: &#34;rsa&#34;,
</span><span style="color:#f1fa8c">    &#34;size&#34;: 2048
</span><span style="color:#f1fa8c">  },
</span><span style="color:#f1fa8c">  &#34;names&#34;: [
</span><span style="color:#f1fa8c">    {
</span><span style="color:#f1fa8c">      &#34;C&#34;: &#34;CN&#34;,
</span><span style="color:#f1fa8c">      &#34;ST&#34;: &#34;BeiJing&#34;,
</span><span style="color:#f1fa8c">      &#34;L&#34;: &#34;BeiJing&#34;,
</span><span style="color:#f1fa8c">      &#34;O&#34;: &#34;system:masters&#34;,
</span><span style="color:#f1fa8c">      &#34;OU&#34;: &#34;System&#34;
</span><span style="color:#f1fa8c">    }
</span><span style="color:#f1fa8c">  ]
</span><span style="color:#f1fa8c">}
</span><span style="color:#f1fa8c">EOF</span>
</code></pre></div><ul>
<li>后续<code>kube-apiserver</code>使用RBAC 对客户端(如kubelet、kube-proxy、Pod)请求进行授权</li>
<li><code>kube-apiserver</code> 预定义了一些RBAC 使用的RoleBindings，如cluster-admin 将Group <code>system:masters</code>与Role <code>cluster-admin</code>绑定，该Role 授予了调用<code>kube-apiserver</code>所有API 的权限</li>
<li>O 指定了该证书的Group 为<code>system:masters</code>，kubectl使用该证书访问<code>kube-apiserver</code>时，由于证书被CA 签名，所以认证通过，同时由于证书用户组为经过预授权的<code>system:masters</code>，所以被授予访问所有API 的劝降</li>
<li>hosts 属性值为空列表</li>
</ul>
<p>生成admin 证书和私钥：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cfssl gencert -ca<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  -ca-key<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca-key.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  -config<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca-config.json <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  -profile<span style="color:#ff79c6">=</span>kubernetes admin-csr.json | cfssljson -bare admin
$ ls admin
admin.csr  admin-csr.json  admin-key.pem  admin.pem
$ sudo mv admin*.pem /etc/kubernetes/ssl/
</code></pre></div><h3 id="创建kubectl-kubeconfig-文件">创建kubectl kubeconfig 文件</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#6272a4"># 设置集群参数</span>
$ kubectl config set-cluster kubernetes <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --certificate-authority<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --embed-certs<span style="color:#ff79c6">=</span><span style="color:#8be9fd;font-style:italic">true</span> <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --server<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">KUBE_APISERVER</span><span style="color:#f1fa8c">}</span>
<span style="color:#6272a4"># 设置客户端认证参数</span>
$ kubectl config set-credentials admin <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --client-certificate<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/admin.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --embed-certs<span style="color:#ff79c6">=</span><span style="color:#8be9fd;font-style:italic">true</span> <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --client-key<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/admin-key.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --token<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">BOOTSTRAP_TOKEN</span><span style="color:#f1fa8c">}</span>
<span style="color:#6272a4"># 设置上下文参数</span>
$ kubectl config set-context kubernetes <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --cluster<span style="color:#ff79c6">=</span>kubernetes <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --user<span style="color:#ff79c6">=</span>admin
<span style="color:#6272a4"># 设置默认上下文</span>
$ kubectl config use-context kubernetes
</code></pre></div><ul>
<li><code>admin.pem</code>证书O 字段值为<code>system:masters</code>，<code>kube-apiserver</code> 预定义的 RoleBinding <code>cluster-admin</code> 将 Group <code>system:masters</code> 与 Role <code>cluster-admin</code> 绑定，该 Role 授予了调用<code>kube-apiserver</code> 相关 API 的权限</li>
<li>生成的kubeconfig 被保存到 <code>~/.kube/config</code> 文件</li>
</ul>
<h3 id="分发kubeconfig-文件">分发kubeconfig 文件</h3>
<p>将<code>~/.kube/config</code>文件拷贝到运行<code>kubectl</code>命令的机器的<code>~/.kube/</code>目录下去。</p>
<h2 id="5-部署flannel-网络a-idflannelda">5. 部署Flannel 网络<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<p>kubernetes 要求集群内各节点能通过Pod 网段互联互通，下面我们来使用Flannel 在所有节点上创建互联互通的Pod 网段的步骤。</p>
<blockquote>
<p>需要在所有的Node节点安装。</p>
</blockquote>
<h3 id="环境变量-1">环境变量</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ <span style="color:#8be9fd;font-style:italic">export</span> <span style="color:#8be9fd;font-style:italic">NODE_IP</span><span style="color:#ff79c6">=</span>192.168.1.137  <span style="color:#6272a4"># 当前部署节点的IP</span>
<span style="color:#6272a4"># 导入全局变量</span>
$ <span style="color:#8be9fd;font-style:italic">source</span> /usr/k8s/bin/env.sh
</code></pre></div><h3 id="创建tls-密钥和证书-1">创建TLS 密钥和证书</h3>
<p>etcd 集群启用了双向TLS 认证，所以需要为flanneld 指定与etcd 集群通信的CA 和密钥。</p>
<p>创建flanneld 证书签名请求：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat &gt; flanneld-csr.json <span style="color:#f1fa8c">&lt;&lt;EOF
</span><span style="color:#f1fa8c">{
</span><span style="color:#f1fa8c">  &#34;CN&#34;: &#34;flanneld&#34;,
</span><span style="color:#f1fa8c">  &#34;hosts&#34;: [],
</span><span style="color:#f1fa8c">  &#34;key&#34;: {
</span><span style="color:#f1fa8c">    &#34;algo&#34;: &#34;rsa&#34;,
</span><span style="color:#f1fa8c">    &#34;size&#34;: 2048
</span><span style="color:#f1fa8c">  },
</span><span style="color:#f1fa8c">  &#34;names&#34;: [
</span><span style="color:#f1fa8c">    {
</span><span style="color:#f1fa8c">      &#34;C&#34;: &#34;CN&#34;,
</span><span style="color:#f1fa8c">      &#34;ST&#34;: &#34;BeiJing&#34;,
</span><span style="color:#f1fa8c">      &#34;L&#34;: &#34;BeiJing&#34;,
</span><span style="color:#f1fa8c">      &#34;O&#34;: &#34;k8s&#34;,
</span><span style="color:#f1fa8c">      &#34;OU&#34;: &#34;System&#34;
</span><span style="color:#f1fa8c">    }
</span><span style="color:#f1fa8c">  ]
</span><span style="color:#f1fa8c">}
</span><span style="color:#f1fa8c">EOF</span>
</code></pre></div><p>生成flanneld 证书和私钥：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cfssl gencert -ca<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  -ca-key<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca-key.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  -config<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca-config.json <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  -profile<span style="color:#ff79c6">=</span>kubernetes flanneld-csr.json | cfssljson -bare flanneld
$ ls flanneld*
flanneld.csr  flanneld-csr.json  flanneld-key.pem flanneld.pem
$ sudo mkdir -p /etc/flanneld/ssl
$ sudo mv flanneld*.pem /etc/flanneld/ssl
</code></pre></div><h3 id="向etcd-写入集群pod-网段信息">向etcd 写入集群Pod 网段信息</h3>
<blockquote>
<p>该步骤只需在第一次部署Flannel 网络时执行，后续在其他节点上部署Flanneld 时无需再写入该信息</p>
</blockquote>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ etcdctl <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --endpoints<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">ETCD_ENDPOINTS</span><span style="color:#f1fa8c">}</span> <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --ca-file<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --cert-file<span style="color:#ff79c6">=</span>/etc/flanneld/ssl/flanneld.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --key-file<span style="color:#ff79c6">=</span>/etc/flanneld/ssl/flanneld-key.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  <span style="color:#8be9fd;font-style:italic">set</span> <span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">FLANNEL_ETCD_PREFIX</span><span style="color:#f1fa8c">}</span>/config <span style="color:#f1fa8c">&#39;{&#34;Network&#34;:&#34;&#39;</span><span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">CLUSTER_CIDR</span><span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">&#39;&#34;, &#34;SubnetLen&#34;: 24, &#34;Backend&#34;: {&#34;Type&#34;: &#34;vxlan&#34;}}&#39;</span>
<span style="color:#6272a4"># 得到如下反馈信息</span>
<span style="color:#ff79c6">{</span><span style="color:#f1fa8c">&#34;Network&#34;</span>:<span style="color:#f1fa8c">&#34;172.30.0.0/16&#34;</span>, <span style="color:#f1fa8c">&#34;SubnetLen&#34;</span>: 24, <span style="color:#f1fa8c">&#34;Backend&#34;</span>: <span style="color:#ff79c6">{</span><span style="color:#f1fa8c">&#34;Type&#34;</span>: <span style="color:#f1fa8c">&#34;vxlan&#34;</span><span style="color:#ff79c6">}}</span>
</code></pre></div><ul>
<li>写入的 Pod 网段(${CLUSTER_CIDR}，172.30.0.0/16) 必须与<code>kube-controller-manager</code> 的 <code>--cluster-cidr</code> 选项值一致；</li>
</ul>
<h3 id="安装和配置flanneld">安装和配置flanneld</h3>
<p>前往<a href="https://github.com/coreos/flannel/releases">flanneld release</a>页面下载最新版的flanneld 二进制文件：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ mkdir flannel
$ wget https://github.com/coreos/flannel/releases/download/v0.9.0/flannel-v0.9.0-linux-amd64.tar.gz
$ tar -xzvf flannel-v0.9.0-linux-amd64.tar.gz -C flannel
$ sudo cp flannel/<span style="color:#ff79c6">{</span>flanneld,mk-docker-opts.sh<span style="color:#ff79c6">}</span> /usr/k8s/bin
</code></pre></div><p>创建flanneld的systemd unit 文件</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat &gt; flanneld.service <span style="color:#f1fa8c">&lt;&lt; EOF
</span><span style="color:#f1fa8c">[Unit]
</span><span style="color:#f1fa8c">Description=Flanneld overlay address etcd agent
</span><span style="color:#f1fa8c">After=network.target
</span><span style="color:#f1fa8c">After=network-online.target
</span><span style="color:#f1fa8c">Wants=network-online.target
</span><span style="color:#f1fa8c">After=etcd.service
</span><span style="color:#f1fa8c">Before=docker.service
</span><span style="color:#f1fa8c">
</span><span style="color:#f1fa8c">[Service]
</span><span style="color:#f1fa8c">Type=notify
</span><span style="color:#f1fa8c">ExecStart=/usr/k8s/bin/flanneld \\
</span><span style="color:#f1fa8c">  -etcd-cafile=/etc/kubernetes/ssl/ca.pem \\
</span><span style="color:#f1fa8c">  -etcd-certfile=/etc/flanneld/ssl/flanneld.pem \\
</span><span style="color:#f1fa8c">  -etcd-keyfile=/etc/flanneld/ssl/flanneld-key.pem \\
</span><span style="color:#f1fa8c">  -etcd-endpoints=${ETCD_ENDPOINTS} \\
</span><span style="color:#f1fa8c">  -etcd-prefix=${FLANNEL_ETCD_PREFIX}
</span><span style="color:#f1fa8c">ExecStartPost=/usr/k8s/bin/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/docker
</span><span style="color:#f1fa8c">Restart=on-failure
</span><span style="color:#f1fa8c">
</span><span style="color:#f1fa8c">[Install]
</span><span style="color:#f1fa8c">WantedBy=multi-user.target
</span><span style="color:#f1fa8c">RequiredBy=docker.service
</span><span style="color:#f1fa8c">EOF</span>
</code></pre></div><ul>
<li><code>mk-docker-opts.sh</code>脚本将分配给flanneld 的Pod 子网网段信息写入到<code>/run/flannel/docker</code> 文件中，后续docker 启动时使用这个文件中的参数值为 docker0 网桥</li>
<li>flanneld 使用系统缺省路由所在的接口和其他节点通信，对于有多个网络接口的机器(内网和公网)，可以用 <code>--iface</code> 选项值指定通信接口(上面的 systemd unit 文件没指定这个选项)</li>
</ul>
<h3 id="启动flanneld">启动flanneld</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo cp flanneld.service /etc/systemd/system/
$ sudo systemctl daemon-reload
$ sudo systemctl <span style="color:#8be9fd;font-style:italic">enable</span> flanneld
$ sudo systemctl start flanneld
$ systemctl status flanneld
</code></pre></div><h3 id="检查flanneld-服务">检查flanneld 服务</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">ifconfig flannel.1
</code></pre></div><h3 id="检查分配给各flanneld-的pod-网段信息">检查分配给各flanneld 的Pod 网段信息</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ <span style="color:#6272a4"># 查看集群 Pod 网段(/16)</span>
$ etcdctl <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --endpoints<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">ETCD_ENDPOINTS</span><span style="color:#f1fa8c">}</span> <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --ca-file<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --cert-file<span style="color:#ff79c6">=</span>/etc/flanneld/ssl/flanneld.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --key-file<span style="color:#ff79c6">=</span>/etc/flanneld/ssl/flanneld-key.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  get <span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">FLANNEL_ETCD_PREFIX</span><span style="color:#f1fa8c">}</span>/config
<span style="color:#ff79c6">{</span> <span style="color:#f1fa8c">&#34;Network&#34;</span>: <span style="color:#f1fa8c">&#34;172.30.0.0/16&#34;</span>, <span style="color:#f1fa8c">&#34;SubnetLen&#34;</span>: 24, <span style="color:#f1fa8c">&#34;Backend&#34;</span>: <span style="color:#ff79c6">{</span> <span style="color:#f1fa8c">&#34;Type&#34;</span>: <span style="color:#f1fa8c">&#34;vxlan&#34;</span> <span style="color:#ff79c6">}</span> <span style="color:#ff79c6">}</span>
$ <span style="color:#6272a4"># 查看已分配的 Pod 子网段列表(/24)</span>
$ etcdctl <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --endpoints<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">ETCD_ENDPOINTS</span><span style="color:#f1fa8c">}</span> <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --ca-file<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --cert-file<span style="color:#ff79c6">=</span>/etc/flanneld/ssl/flanneld.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --key-file<span style="color:#ff79c6">=</span>/etc/flanneld/ssl/flanneld-key.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  ls <span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">FLANNEL_ETCD_PREFIX</span><span style="color:#f1fa8c">}</span>/subnets
/kubernetes/network/subnets/172.30.77.0-24
$ <span style="color:#6272a4"># 查看某一 Pod 网段对应的 flanneld 进程监听的 IP 和网络参数</span>
$ etcdctl <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --endpoints<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">ETCD_ENDPOINTS</span><span style="color:#f1fa8c">}</span> <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --ca-file<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --cert-file<span style="color:#ff79c6">=</span>/etc/flanneld/ssl/flanneld.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --key-file<span style="color:#ff79c6">=</span>/etc/flanneld/ssl/flanneld-key.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  get <span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">FLANNEL_ETCD_PREFIX</span><span style="color:#f1fa8c">}</span>/subnets/172.30.77.0-24
<span style="color:#ff79c6">{</span><span style="color:#f1fa8c">&#34;PublicIP&#34;</span>:<span style="color:#f1fa8c">&#34;192.168.1.137&#34;</span>,<span style="color:#f1fa8c">&#34;BackendType&#34;</span>:<span style="color:#f1fa8c">&#34;vxlan&#34;</span>,<span style="color:#f1fa8c">&#34;BackendData&#34;</span>:<span style="color:#ff79c6">{</span><span style="color:#f1fa8c">&#34;VtepMAC&#34;</span>:<span style="color:#f1fa8c">&#34;62:fc:03:83:1b:2b&#34;</span><span style="color:#ff79c6">}}</span>
</code></pre></div><h3 id="确保各节点间pod-网段能互联互通">确保各节点间Pod 网段能互联互通</h3>
<p>在各个节点部署完Flanneld 后，查看已分配的Pod 子网段列表：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ etcdctl <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --endpoints<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">ETCD_ENDPOINTS</span><span style="color:#f1fa8c">}</span> <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --ca-file<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --cert-file<span style="color:#ff79c6">=</span>/etc/flanneld/ssl/flanneld.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --key-file<span style="color:#ff79c6">=</span>/etc/flanneld/ssl/flanneld-key.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  ls <span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">FLANNEL_ETCD_PREFIX</span><span style="color:#f1fa8c">}</span>/subnets

/kubernetes/network/subnets/172.30.19.0-24
/kubernetes/network/subnets/172.30.30.0-24
/kubernetes/network/subnets/172.30.77.0-24
/kubernetes/network/subnets/172.30.41.0-24
/kubernetes/network/subnets/172.30.83.0-24
</code></pre></div><p>当前五个节点分配的 Pod 网段分别是：172.30.77.0-24、172.30.30.0-24、172.30.19.0-24、172.30.41.0-24、172.30.83.0-24。</p>
<h2 id="6-部署master-节点a-idmastera">6. 部署master 节点<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<p>kubernetes master 节点包含的组件有：</p>
<ul>
<li>kube-apiserver</li>
<li>kube-scheduler</li>
<li>kube-controller-manager</li>
</ul>
<p>目前这3个组件需要部署到同一台机器上：（后面再部署高可用的master）</p>
<ul>
<li><code>kube-scheduler</code>、<code>kube-controller-manager</code> 和 <code>kube-apiserver</code> 三者的功能紧密相关；</li>
<li>同时只能有一个 <code>kube-scheduler</code>、<code>kube-controller-manager</code> 进程处于工作状态，如果运行多个，则需要通过选举产生一个 leader；</li>
</ul>
<p>master 节点与node 节点上的Pods 通过Pod 网络通信，所以需要在master 节点上部署Flannel 网络。</p>
<h3 id="环境变量-2">环境变量</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ <span style="color:#8be9fd;font-style:italic">export</span> <span style="color:#8be9fd;font-style:italic">NODE_IP</span><span style="color:#ff79c6">=</span>192.168.1.137  <span style="color:#6272a4"># 当前部署的master 机器IP</span>
$ <span style="color:#8be9fd;font-style:italic">source</span> /usr/k8s/bin/env.sh
</code></pre></div><h3 id="下载最新版本的二进制文件">下载最新版本的二进制文件</h3>
<p>在<a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.8.md#server-binaries">kubernetes changelog</a> 页面下载最新版本的文件：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ wget https://dl.k8s.io/v1.8.2/kubernetes-server-linux-amd64.tar.gz
$ tar -xzvf kubernetes-server-linux-amd64.tar.gz
</code></pre></div><p>将二进制文件拷贝到<code>/usr/k8s/bin</code>目录</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo cp -r server/bin/<span style="color:#ff79c6">{</span>kube-apiserver,kube-controller-manager,kube-scheduler<span style="color:#ff79c6">}</span> /usr/k8s/bin/
</code></pre></div><h3 id="创建kubernetes-证书">创建kubernetes 证书</h3>
<p>创建kubernetes 证书签名请求：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat &gt; kubernetes-csr.json <span style="color:#f1fa8c">&lt;&lt;EOF
</span><span style="color:#f1fa8c">{
</span><span style="color:#f1fa8c">  &#34;CN&#34;: &#34;kubernetes&#34;,
</span><span style="color:#f1fa8c">  &#34;hosts&#34;: [
</span><span style="color:#f1fa8c">    &#34;127.0.0.1&#34;,
</span><span style="color:#f1fa8c">    &#34;${NODE_IP}&#34;,
</span><span style="color:#f1fa8c">    &#34;${MASTER_URL}&#34;,
</span><span style="color:#f1fa8c">    &#34;${CLUSTER_KUBERNETES_SVC_IP}&#34;,
</span><span style="color:#f1fa8c">    &#34;kubernetes&#34;,
</span><span style="color:#f1fa8c">    &#34;kubernetes.default&#34;,
</span><span style="color:#f1fa8c">    &#34;kubernetes.default.svc&#34;,
</span><span style="color:#f1fa8c">    &#34;kubernetes.default.svc.cluster&#34;,
</span><span style="color:#f1fa8c">    &#34;kubernetes.default.svc.cluster.local&#34;
</span><span style="color:#f1fa8c">  ],
</span><span style="color:#f1fa8c">  &#34;key&#34;: {
</span><span style="color:#f1fa8c">    &#34;algo&#34;: &#34;rsa&#34;,
</span><span style="color:#f1fa8c">    &#34;size&#34;: 2048
</span><span style="color:#f1fa8c">  },
</span><span style="color:#f1fa8c">  &#34;names&#34;: [
</span><span style="color:#f1fa8c">    {
</span><span style="color:#f1fa8c">      &#34;C&#34;: &#34;CN&#34;,
</span><span style="color:#f1fa8c">      &#34;ST&#34;: &#34;BeiJing&#34;,
</span><span style="color:#f1fa8c">      &#34;L&#34;: &#34;BeiJing&#34;,
</span><span style="color:#f1fa8c">      &#34;O&#34;: &#34;k8s&#34;,
</span><span style="color:#f1fa8c">      &#34;OU&#34;: &#34;System&#34;
</span><span style="color:#f1fa8c">    }
</span><span style="color:#f1fa8c">  ]
</span><span style="color:#f1fa8c">}
</span><span style="color:#f1fa8c">EOF</span>
</code></pre></div><ul>
<li>如果 hosts 字段不为空则需要指定授权使用该证书的 <strong>IP 或域名列表</strong>，所以上面分别指定了当前部署的 master 节点主机 IP 以及apiserver 负载的内部域名</li>
<li>还需要添加 kube-apiserver 注册的名为 <code>kubernetes</code> 的服务 IP (Service Cluster IP)，一般是 kube-apiserver <code>--service-cluster-ip-range</code> 选项值指定的网段的<strong>第一个IP</strong>，如 &ldquo;10.254.0.1&rdquo;</li>
</ul>
<p>生成kubernetes 证书和私钥：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cfssl gencert -ca<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  -ca-key<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca-key.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  -config<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca-config.json <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  -profile<span style="color:#ff79c6">=</span>kubernetes kubernetes-csr.json | cfssljson -bare kubernetes
$ ls kubernetes*
kubernetes.csr  kubernetes-csr.json  kubernetes-key.pem  kubernetes.pem
$ sudo mkdir -p /etc/kubernetes/ssl/
$ sudo mv kubernetes*.pem /etc/kubernetes/ssl/
</code></pre></div><h3 id="61-配置和启动kube-apiserver">6.1 配置和启动kube-apiserver</h3>
<h4 id="创建kube-apiserver-使用的客户端token-文件">创建kube-apiserver 使用的客户端token 文件</h4>
<p>kubelet 首次启动时向kube-apiserver 发送TLS Bootstrapping 请求，kube-apiserver 验证请求中的token 是否与它配置的token.csv 一致，如果一致则自动为kubelet 生成证书和密钥。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ <span style="color:#6272a4"># 导入的 environment.sh 文件定义了 BOOTSTRAP_TOKEN 变量</span>
$ cat &gt; token.csv <span style="color:#f1fa8c">&lt;&lt;EOF
</span><span style="color:#f1fa8c">${BOOTSTRAP_TOKEN},kubelet-bootstrap,10001,&#34;system:kubelet-bootstrap&#34;
</span><span style="color:#f1fa8c">EOF</span>
$ sudo mv token.csv /etc/kubernetes/
</code></pre></div><h4 id="创建kube-apiserver-的systemd-unit文件">创建kube-apiserver 的systemd unit文件</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat  &gt; kube-apiserver.service <span style="color:#f1fa8c">&lt;&lt;EOF
</span><span style="color:#f1fa8c">[Unit]
</span><span style="color:#f1fa8c">Description=Kubernetes API Server
</span><span style="color:#f1fa8c">Documentation=https://github.com/GoogleCloudPlatform/kubernetes
</span><span style="color:#f1fa8c">After=network.target
</span><span style="color:#f1fa8c">
</span><span style="color:#f1fa8c">[Service]
</span><span style="color:#f1fa8c">ExecStart=/usr/k8s/bin/kube-apiserver \\
</span><span style="color:#f1fa8c">  --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \\
</span><span style="color:#f1fa8c">  --advertise-address=${NODE_IP} \\
</span><span style="color:#f1fa8c">  --bind-address=0.0.0.0 \\
</span><span style="color:#f1fa8c">  --insecure-bind-address=${NODE_IP} \\
</span><span style="color:#f1fa8c">  --authorization-mode=Node,RBAC \\
</span><span style="color:#f1fa8c">  --runtime-config=rbac.authorization.k8s.io/v1alpha1 \\
</span><span style="color:#f1fa8c">  --kubelet-https=true \\
</span><span style="color:#f1fa8c">  --experimental-bootstrap-token-auth \\
</span><span style="color:#f1fa8c">  --token-auth-file=/etc/kubernetes/token.csv \\
</span><span style="color:#f1fa8c">  --service-cluster-ip-range=${SERVICE_CIDR} \\
</span><span style="color:#f1fa8c">  --service-node-port-range=${NODE_PORT_RANGE} \\
</span><span style="color:#f1fa8c">  --tls-cert-file=/etc/kubernetes/ssl/kubernetes.pem \\
</span><span style="color:#f1fa8c">  --tls-private-key-file=/etc/kubernetes/ssl/kubernetes-key.pem \\
</span><span style="color:#f1fa8c">  --client-ca-file=/etc/kubernetes/ssl/ca.pem \\
</span><span style="color:#f1fa8c">  --service-account-key-file=/etc/kubernetes/ssl/ca-key.pem \\
</span><span style="color:#f1fa8c">  --etcd-cafile=/etc/kubernetes/ssl/ca.pem \\
</span><span style="color:#f1fa8c">  --etcd-certfile=/etc/kubernetes/ssl/kubernetes.pem \\
</span><span style="color:#f1fa8c">  --etcd-keyfile=/etc/kubernetes/ssl/kubernetes-key.pem \\
</span><span style="color:#f1fa8c">  --etcd-servers=${ETCD_ENDPOINTS} \\
</span><span style="color:#f1fa8c">  --enable-swagger-ui=true \\
</span><span style="color:#f1fa8c">  --allow-privileged=true \\
</span><span style="color:#f1fa8c">  --apiserver-count=2 \\
</span><span style="color:#f1fa8c">  --audit-log-maxage=30 \\
</span><span style="color:#f1fa8c">  --audit-log-maxbackup=3 \\
</span><span style="color:#f1fa8c">  --audit-log-maxsize=100 \\
</span><span style="color:#f1fa8c">  --audit-log-path=/var/lib/audit.log \\
</span><span style="color:#f1fa8c">  --audit-policy-file=/etc/kubernetes/audit-policy.yaml \\
</span><span style="color:#f1fa8c">  --event-ttl=1h \\
</span><span style="color:#f1fa8c">  --logtostderr=true \\
</span><span style="color:#f1fa8c">  --v=6
</span><span style="color:#f1fa8c">Restart=on-failure
</span><span style="color:#f1fa8c">RestartSec=5
</span><span style="color:#f1fa8c">Type=notify
</span><span style="color:#f1fa8c">LimitNOFILE=65536
</span><span style="color:#f1fa8c">
</span><span style="color:#f1fa8c">[Install]
</span><span style="color:#f1fa8c">WantedBy=multi-user.target
</span><span style="color:#f1fa8c">EOF</span>
</code></pre></div><ul>
<li>如果你安装的是<strong>1.9.x</strong>版本的，一定要记住上面的参数<code>experimental-bootstrap-token-auth</code>，需要替换成<code>enable-bootstrap-token-auth</code>，因为这个参数在<strong>1.9.x</strong>里面已经废弃掉了</li>
<li>kube-apiserver 1.6 版本开始使用 etcd v3 API 和存储格式</li>
<li><code>--authorization-mode=RBAC</code> 指定在安全端口使用RBAC 授权模式，拒绝未通过授权的请求</li>
<li>kube-scheduler、kube-controller-manager 一般和 kube-apiserver 部署在同一台机器上，它们使用<strong>非安全端口</strong>和 kube-apiserver通信</li>
<li>kubelet、kube-proxy、kubectl 部署在其它 Node 节点上，如果通过<strong>安全端口</strong>访问 kube-apiserver，则必须先通过 TLS 证书认证，再通过 RBAC 授权</li>
<li>kube-proxy、kubectl 通过使用证书里指定相关的 User、Group 来达到通过 RBAC 授权的目的</li>
<li>如果使用了 kubelet TLS Boostrap 机制，则不能再指定 <code>--kubelet-certificate-authority</code>、<code>--kubelet-client-certificate</code> 和 <code>--kubelet-client-key</code> 选项，否则后续 kube-apiserver 校验 kubelet 证书时出现 ”x509: certificate signed by unknown authority“ 错误</li>
<li><code>--admission-control</code> 值必须包含 <code>ServiceAccount</code>，否则部署集群插件时会失败</li>
<li><code>--bind-address</code> 不能为 <code>127.0.0.1</code></li>
<li><code>--service-cluster-ip-range</code> 指定 Service Cluster IP 地址段，该地址段不能路由可达</li>
<li><code>--service-node-port-range=${NODE_PORT_RANGE}</code> 指定 NodePort 的端口范围</li>
<li>缺省情况下 kubernetes 对象保存在<code>etcd/registry</code> 路径下，可以通过 <code>--etcd-prefix</code> 参数进行调整</li>
<li>kube-apiserver 1.8版本后需要在<code>--authorization-mode</code>参数中添加<code>Node</code>，即：<code>--authorization-mode=Node,RBAC</code>，否则Node 节点无法注册</li>
<li>注意要开启审查日志功能，指定<code>--audit-log-path</code>参数是不够的，这只是指定了日志的路径，还需要指定一个审查日志策略文件：<code>--audit-policy-file</code>，我们也可以使用日志收集工具收集相关的日志进行分析。</li>
</ul>
<p>审查日志策略文件内容如下：（<strong>/etc/kubernetes/audit-policy.yaml</strong>）</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#ff79c6">apiVersion</span>: audit.k8s.io/v1beta1 <span style="color:#6272a4"># This is required.</span>
<span style="color:#ff79c6">kind</span>: Policy
<span style="color:#6272a4"># Don&#39;t generate audit events for all requests in RequestReceived stage.</span>
<span style="color:#ff79c6">omitStages</span>:
  - <span style="color:#f1fa8c">&#34;RequestReceived&#34;</span>
<span style="color:#ff79c6">rules</span>:
  <span style="color:#6272a4"># Log pod changes at RequestResponse level</span>
  - <span style="color:#ff79c6">level</span>: RequestResponse
    <span style="color:#ff79c6">resources</span>:
    - <span style="color:#ff79c6">group</span>: <span style="color:#f1fa8c">&#34;&#34;</span>
      <span style="color:#6272a4"># Resource &#34;pods&#34; doesn&#39;t match requests to any subresource of pods,</span>
      <span style="color:#6272a4"># which is consistent with the RBAC policy.</span>
      <span style="color:#ff79c6">resources</span>: [<span style="color:#f1fa8c">&#34;pods&#34;</span>]
  <span style="color:#6272a4"># Log &#34;pods/log&#34;, &#34;pods/status&#34; at Metadata level</span>
  - <span style="color:#ff79c6">level</span>: Metadata
    <span style="color:#ff79c6">resources</span>:
    - <span style="color:#ff79c6">group</span>: <span style="color:#f1fa8c">&#34;&#34;</span>
      <span style="color:#ff79c6">resources</span>: [<span style="color:#f1fa8c">&#34;pods/log&#34;</span>, <span style="color:#f1fa8c">&#34;pods/status&#34;</span>]

  <span style="color:#6272a4"># Don&#39;t log requests to a configmap called &#34;controller-leader&#34;</span>
  - <span style="color:#ff79c6">level</span>: None
    <span style="color:#ff79c6">resources</span>:
    - <span style="color:#ff79c6">group</span>: <span style="color:#f1fa8c">&#34;&#34;</span>
      <span style="color:#ff79c6">resources</span>: [<span style="color:#f1fa8c">&#34;configmaps&#34;</span>]
      <span style="color:#ff79c6">resourceNames</span>: [<span style="color:#f1fa8c">&#34;controller-leader&#34;</span>]

  <span style="color:#6272a4"># Don&#39;t log watch requests by the &#34;system:kube-proxy&#34; on endpoints or services</span>
  - <span style="color:#ff79c6">level</span>: None
    <span style="color:#ff79c6">users</span>: [<span style="color:#f1fa8c">&#34;system:kube-proxy&#34;</span>]
    <span style="color:#ff79c6">verbs</span>: [<span style="color:#f1fa8c">&#34;watch&#34;</span>]
    <span style="color:#ff79c6">resources</span>:
    - <span style="color:#ff79c6">group</span>: <span style="color:#f1fa8c">&#34;&#34;</span> <span style="color:#6272a4"># core API group</span>
      <span style="color:#ff79c6">resources</span>: [<span style="color:#f1fa8c">&#34;endpoints&#34;</span>, <span style="color:#f1fa8c">&#34;services&#34;</span>]

  <span style="color:#6272a4"># Don&#39;t log authenticated requests to certain non-resource URL paths.</span>
  - <span style="color:#ff79c6">level</span>: None
    <span style="color:#ff79c6">userGroups</span>: [<span style="color:#f1fa8c">&#34;system:authenticated&#34;</span>]
    <span style="color:#ff79c6">nonResourceURLs</span>:
    - <span style="color:#f1fa8c">&#34;/api*&#34;</span> <span style="color:#6272a4"># Wildcard matching.</span>
    - <span style="color:#f1fa8c">&#34;/version&#34;</span>

  <span style="color:#6272a4"># Log the request body of configmap changes in kube-system.</span>
  - <span style="color:#ff79c6">level</span>: Request
    <span style="color:#ff79c6">resources</span>:
    - <span style="color:#ff79c6">group</span>: <span style="color:#f1fa8c">&#34;&#34;</span> <span style="color:#6272a4"># core API group</span>
      <span style="color:#ff79c6">resources</span>: [<span style="color:#f1fa8c">&#34;configmaps&#34;</span>]
    <span style="color:#6272a4"># This rule only applies to resources in the &#34;kube-system&#34; namespace.</span>
    <span style="color:#6272a4"># The empty string &#34;&#34; can be used to select non-namespaced resources.</span>
    <span style="color:#ff79c6">namespaces</span>: [<span style="color:#f1fa8c">&#34;kube-system&#34;</span>]

  <span style="color:#6272a4"># Log configmap and secret changes in all other namespaces at the Metadata level.</span>
  - <span style="color:#ff79c6">level</span>: Metadata
    <span style="color:#ff79c6">resources</span>:
    - <span style="color:#ff79c6">group</span>: <span style="color:#f1fa8c">&#34;&#34;</span> <span style="color:#6272a4"># core API group</span>
      <span style="color:#ff79c6">resources</span>: [<span style="color:#f1fa8c">&#34;secrets&#34;</span>, <span style="color:#f1fa8c">&#34;configmaps&#34;</span>]

  <span style="color:#6272a4"># Log all other resources in core and extensions at the Request level.</span>
  - <span style="color:#ff79c6">level</span>: Request
    <span style="color:#ff79c6">resources</span>:
    - <span style="color:#ff79c6">group</span>: <span style="color:#f1fa8c">&#34;&#34;</span> <span style="color:#6272a4"># core API group</span>
    - <span style="color:#ff79c6">group</span>: <span style="color:#f1fa8c">&#34;extensions&#34;</span> <span style="color:#6272a4"># Version of group should NOT be included.</span>

  <span style="color:#6272a4"># A catch-all rule to log all other requests at the Metadata level.</span>
  - <span style="color:#ff79c6">level</span>: Metadata
    <span style="color:#6272a4"># Long-running requests like watches that fall under this rule will not</span>
    <span style="color:#6272a4"># generate an audit event in RequestReceived.</span>
    <span style="color:#ff79c6">omitStages</span>:
      - <span style="color:#f1fa8c">&#34;RequestReceived&#34;</span>
</code></pre></div><p>审查日志的相关配置可以查看文档了解：<a href="https://kubernetes.io/docs/tasks/debug-application-cluster/audit/">https://kubernetes.io/docs/tasks/debug-application-cluster/audit/</a></p>
<h4 id="启动kube-apiserver">启动kube-apiserver</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo cp kube-apiserver.service /etc/systemd/system/
$ sudo systemctl daemon-reload
$ sudo systemctl <span style="color:#8be9fd;font-style:italic">enable</span> kube-apiserver
$ sudo systemctl start kube-apiserver
$ sudo systemctl status kube-apiserver
</code></pre></div><h3 id="62-配置和启动kube-controller-manager">6.2 配置和启动kube-controller-manager</h3>
<h4 id="创建kube-controller-manager-的systemd-unit-文件">创建kube-controller-manager 的systemd unit 文件</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat &gt; kube-controller-manager.service <span style="color:#f1fa8c">&lt;&lt;EOF
</span><span style="color:#f1fa8c">[Unit]
</span><span style="color:#f1fa8c">Description=Kubernetes Controller Manager
</span><span style="color:#f1fa8c">Documentation=https://github.com/GoogleCloudPlatform/kubernetes
</span><span style="color:#f1fa8c">
</span><span style="color:#f1fa8c">[Service]
</span><span style="color:#f1fa8c">ExecStart=/usr/k8s/bin/kube-controller-manager \\
</span><span style="color:#f1fa8c">  --address=127.0.0.1 \\
</span><span style="color:#f1fa8c">  --master=http://${MASTER_URL}:8080 \\
</span><span style="color:#f1fa8c">  --allocate-node-cidrs=true \\
</span><span style="color:#f1fa8c">  --service-cluster-ip-range=${SERVICE_CIDR} \\
</span><span style="color:#f1fa8c">  --cluster-cidr=${CLUSTER_CIDR} \\
</span><span style="color:#f1fa8c">  --cluster-name=kubernetes \\
</span><span style="color:#f1fa8c">  --cluster-signing-cert-file=/etc/kubernetes/ssl/ca.pem \\
</span><span style="color:#f1fa8c">  --cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem \\
</span><span style="color:#f1fa8c">  --service-account-private-key-file=/etc/kubernetes/ssl/ca-key.pem \\
</span><span style="color:#f1fa8c">  --root-ca-file=/etc/kubernetes/ssl/ca.pem \\
</span><span style="color:#f1fa8c">  --leader-elect=true \\
</span><span style="color:#f1fa8c">  --v=2
</span><span style="color:#f1fa8c">Restart=on-failure
</span><span style="color:#f1fa8c">RestartSec=5
</span><span style="color:#f1fa8c">
</span><span style="color:#f1fa8c">[Install]
</span><span style="color:#f1fa8c">WantedBy=multi-user.target
</span><span style="color:#f1fa8c">EOF</span>
</code></pre></div><ul>
<li><code>--address</code> 值必须为 <code>127.0.0.1</code>，因为当前 kube-apiserver 期望 scheduler 和 controller-manager 在同一台机器</li>
</ul>
<ul>
<li><code>--master=http://${MASTER_URL}:8080</code>：使用<code>http</code>(非安全端口)与 kube-apiserver 通信，需要下面的<code>haproxy</code>安装成功后才能去掉8080端口。</li>
<li><code>--cluster-cidr</code> 指定 Cluster 中 Pod 的 CIDR 范围，该网段在各 Node 间必须路由可达(flanneld保证)</li>
<li><code>--service-cluster-ip-range</code> 参数指定 Cluster 中 Service 的CIDR范围，该网络在各 Node 间必须路由不可达，必须和 kube-apiserver 中的参数一致</li>
<li><code>--cluster-signing-*</code> 指定的证书和私钥文件用来签名为 TLS BootStrap 创建的证书和私钥</li>
<li><code>--root-ca-file</code> 用来对 kube-apiserver 证书进行校验，<strong>指定该参数后，才会在Pod 容器的 ServiceAccount 中放置该 CA 证书文件</strong></li>
<li><code>--leader-elect=true</code> 部署多台机器组成的 master 集群时选举产生一处于工作状态的 <code>kube-controller-manager</code> 进程</li>
</ul>
<h4 id="启动kube-controller-manager">启动kube-controller-manager</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo cp kube-controller-manager.service /etc/systemd/system/
$ sudo systemctl daemon-reload
$ sudo systemctl <span style="color:#8be9fd;font-style:italic">enable</span> kube-controller-manager
$ sudo systemctl start kube-controller-manager
$ sudo systemctl status kube-controller-manager
</code></pre></div><h3 id="63-配置和启动kube-scheduler">6.3 配置和启动kube-scheduler</h3>
<h4 id="创建kube-scheduler-的systemd-unit文件">创建kube-scheduler 的systemd unit文件</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat &gt; kube-scheduler.service <span style="color:#f1fa8c">&lt;&lt;EOF
</span><span style="color:#f1fa8c">[Unit]
</span><span style="color:#f1fa8c">Description=Kubernetes Scheduler
</span><span style="color:#f1fa8c">Documentation=https://github.com/GoogleCloudPlatform/kubernetes
</span><span style="color:#f1fa8c">
</span><span style="color:#f1fa8c">[Service]
</span><span style="color:#f1fa8c">ExecStart=/usr/k8s/bin/kube-scheduler \\
</span><span style="color:#f1fa8c">  --address=127.0.0.1 \\
</span><span style="color:#f1fa8c">  --master=http://${MASTER_URL}:8080 \\
</span><span style="color:#f1fa8c">  --leader-elect=true \\
</span><span style="color:#f1fa8c">  --v=2
</span><span style="color:#f1fa8c">Restart=on-failure
</span><span style="color:#f1fa8c">RestartSec=5
</span><span style="color:#f1fa8c">
</span><span style="color:#f1fa8c">[Install]
</span><span style="color:#f1fa8c">WantedBy=multi-user.target
</span><span style="color:#f1fa8c">EOF</span>
</code></pre></div><ul>
<li><code>--address</code> 值必须为 <code>127.0.0.1</code>，因为当前 kube-apiserver 期望 scheduler 和 controller-manager 在同一台机器</li>
<li><code>--master=http://${MASTER_URL}:8080</code>：使用<code>http</code>(非安全端口)与 kube-apiserver 通信，需要下面的<code>haproxy</code>启动成功后才能去掉8080端口</li>
<li><code>--leader-elect=true</code> 部署多台机器组成的 master 集群时选举产生一处于工作状态的 <code>kube-controller-manager</code> 进程</li>
</ul>
<h4 id="启动kube-scheduler">启动kube-scheduler</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo cp kube-scheduler.service /etc/systemd/system/
$ sudo systemctl daemon-reload
$ sudo systemctl <span style="color:#8be9fd;font-style:italic">enable</span> kube-scheduler
$ sudo systemctl start kube-scheduler
$ sudo systemctl status kube-scheduler
</code></pre></div><h3 id="64-验证master-节点">6.4 验证master 节点</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl get componentstatuses
NAME                 STATUS    MESSAGE              ERROR
scheduler            Healthy   ok
controller-manager   Healthy   ok
etcd-1               Healthy   <span style="color:#ff79c6">{</span><span style="color:#f1fa8c">&#34;health&#34;</span>: <span style="color:#f1fa8c">&#34;true&#34;</span><span style="color:#ff79c6">}</span>
etcd-2               Healthy   <span style="color:#ff79c6">{</span><span style="color:#f1fa8c">&#34;health&#34;</span>: <span style="color:#f1fa8c">&#34;true&#34;</span><span style="color:#ff79c6">}</span>
etcd-0               Healthy   <span style="color:#ff79c6">{</span><span style="color:#f1fa8c">&#34;health&#34;</span>: <span style="color:#f1fa8c">&#34;true&#34;</span><span style="color:#ff79c6">}</span>
</code></pre></div><h2 id="7-kube-apiserver-高可用a-idhaa">7. kube-apiserver 高可用<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<p>按照上面的方式在<code>master01</code>与<code>master02</code>机器上安装<code>kube-apiserver</code>、<code>kube-controller-manager</code>、<code>kube-scheduler</code>，但是现在我们还是手动指定访问的6443和8080端口的，因为我们的域名<code>k8s-api.virtual.local</code>对应的<code>master01</code>节点直接通过http 和https 还不能访问，这里我们使用<code>haproxy</code> 来代替请求。</p>
<blockquote>
<p>明白什么意思吗？就是我们需要将http默认的80端口请求转发到<code>apiserver</code>的8080端口，将https默认的443端口请求转发到<code>apiserver</code>的6443端口，所以我们这里使用<code>haproxy</code>来做请求转发。</p>
</blockquote>
<h3 id="安装haproxy">安装haproxy</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ yum install -y haproxy
</code></pre></div><h3 id="配置haproxy">配置haproxy</h3>
<p>由于集群内部有的组建是通过非安全端口访问apiserver 的，有的是通过安全端口访问apiserver 的，所以我们要配置http 和https 两种代理方式，配置文件 <code>/etc/haproxy/haproxy.cfg</code>：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">listen stats
  <span style="color:#8be9fd;font-style:italic">bind</span>    *:9000
  mode    http
  stats   <span style="color:#8be9fd;font-style:italic">enable</span>
  stats   hide-version
  stats   uri       /stats
  stats   refresh   30s
  stats   realm     Haproxy<span style="color:#f1fa8c">\ </span>Statistics
  stats   auth      Admin:Password

frontend k8s-api
    <span style="color:#8be9fd;font-style:italic">bind</span> 192.168.1.137:443
    mode tcp
    option tcplog
    tcp-request inspect-delay 5s
    tcp-request content accept <span style="color:#ff79c6">if</span> <span style="color:#ff79c6">{</span> req.ssl_hello_type <span style="color:#bd93f9">1</span> <span style="color:#ff79c6">}</span>
    default_backend k8s-api

backend k8s-api
    mode tcp
    option tcplog
    option tcp-check
    balance roundrobin
    default-server inter 10s downinter 5s rise <span style="color:#bd93f9">2</span> fall <span style="color:#bd93f9">2</span> slowstart 60s maxconn <span style="color:#bd93f9">250</span> maxqueue <span style="color:#bd93f9">256</span> weight <span style="color:#bd93f9">100</span>
    server k8s-api-1 192.168.1.137:6443 check
    server k8s-api-2 192.168.1.138:6443 check

frontend k8s-http-api
    <span style="color:#8be9fd;font-style:italic">bind</span> 192.168.1.137:80
    mode tcp
    option tcplog
    default_backend k8s-http-api

backend k8s-http-api
    mode tcp
    option tcplog
    option tcp-check
    balance roundrobin
    default-server inter 10s downinter 5s rise <span style="color:#bd93f9">2</span> fall <span style="color:#bd93f9">2</span> slowstart 60s maxconn <span style="color:#bd93f9">250</span> maxqueue <span style="color:#bd93f9">256</span> weight <span style="color:#bd93f9">100</span>
    server k8s-http-api-1 192.168.1.137:8080 check
    server k8s-http-api-2 192.168.1.138:8080 check
</code></pre></div><p>通过上面的配置文件我们可以看出通过<code>https</code>的访问将请求转发给apiserver 的6443端口了，http的请求转发到了apiserver 的8080端口。</p>
<h3 id="启动haproxy">启动haproxy</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo systemctl start haproxy
$ sudo systemctl <span style="color:#8be9fd;font-style:italic">enable</span> haproxy
$ sudo systemctl status haproxy
</code></pre></div><p>然后我们可以通过上面<code>9000</code>端口监控我们的<code>haproxy</code>的运行状态(<code>192.168.1.137:9000/stats</code>):</p>
<p>
  <img src="/img/posts/1510279991107.jpg" alt="haproxy stats">

</p>
<h3 id="问题">问题</h3>
<p>上面我们的<code>haproxy</code>的确可以代理我们的两个master 上的apiserver 了，但是还不是高可用的，如果master01 这个节点down 掉了，那么我们haproxy 就不能正常提供服务了。这里我们可以使用两种方法来实现高可用</p>
<h4 id="方式1使用阿里云slb">方式1：使用阿里云SLB</h4>
<p>这种方式实际上是最省心的，在阿里云上建一个内网的SLB，将master01 与master02 添加到SLB 机器组中，转发80(http)和443(https)端口即可（注意下面的提示）</p>
<blockquote>
<p>注意：阿里云的负载均衡是四层TCP负责，不支持后端ECS实例既作为Real Server又作为客户端向所在的负载均衡实例发送请求。因为返回的数据包只在云服务器内部转发，不经过负载均衡，所以在后端ECS实例上去访问负载均衡的服务地址是不通的。什么意思？就是如果你要使用阿里云的SLB的话，那么你不能在<code>apiserver</code>节点上使用SLB（比如在apiserver 上安装kubectl，然后将apiserver的地址设置为SLB的负载地址使用），因为这样的话就可能造成回环了，所以简单的做法是另外用两个新的节点做<code>HA</code>实例，然后将这两个实例添加到<code>SLB</code> 机器组中。</p>
</blockquote>
<!-- raw HTML omitted -->
<h4 id="方式2使用keepalived">方式2：使用keepalived</h4>
<p><code>KeepAlived</code> 是一个高可用方案，通过 VIP（即虚拟 IP）和心跳检测来实现高可用。其原理是存在一组（两台）服务器，分别赋予 Master、Backup 两个角色，默认情况下Master 会绑定VIP 到自己的网卡上，对外提供服务。Master、Backup 会在一定的时间间隔向对方发送心跳数据包来检测对方的状态，这个时间间隔一般为 2 秒钟，如果Backup 发现Master 宕机，那么Backup 会发送ARP 包到网关，把VIP 绑定到自己的网卡，此时Backup 对外提供服务，实现自动化的故障转移，当Master 恢复的时候会重新接管服务。非常类似于路由器中的虚拟路由器冗余协议（VRRP）</p>
<p>开启路由转发，这里我们定义虚拟IP为：<strong>192.168.1.139</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ vi /etc/sysctl.conf
<span style="color:#6272a4"># 添加以下内容</span>
net.ipv4.ip_forward <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">1</span>
net.ipv4.ip_nonlocal_bind <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">1</span>

<span style="color:#6272a4"># 验证并生效</span>
$ sysctl -p
<span style="color:#6272a4"># 验证是否生效</span>
$ cat /proc/sys/net/ipv4/ip_forward
<span style="color:#bd93f9">1</span>
</code></pre></div><p>安装<code>keepalived</code>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ yum install -y keepalived
</code></pre></div><p>我们这里将master01 设置为Master，master02 设置为Backup，修改配置：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ vi /etc/keepalived/keepalived.conf
! Configuration File <span style="color:#ff79c6">for</span> keepalived

global_defs <span style="color:#ff79c6">{</span>
   notification_email <span style="color:#ff79c6">{</span>
   <span style="color:#ff79c6">}</span>
   router_id kube_api
<span style="color:#ff79c6">}</span>

vrrp_script check_haproxy <span style="color:#ff79c6">{</span>
    <span style="color:#6272a4"># 自身状态检测</span>
    script <span style="color:#f1fa8c">&#34;killall -0 haproxy&#34;</span>
    interval <span style="color:#bd93f9">3</span>
    weight <span style="color:#bd93f9">5</span>
<span style="color:#ff79c6">}</span>

vrrp_instance haproxy-vip <span style="color:#ff79c6">{</span>
    <span style="color:#6272a4"># 使用单播通信，默认是组播通信</span>
    unicast_src_ip 192.168.1.137
    unicast_peer <span style="color:#ff79c6">{</span>
        192.168.1.138
    <span style="color:#ff79c6">}</span>
    <span style="color:#6272a4"># 初始化状态</span>
    state MASTER
    <span style="color:#6272a4"># 虚拟ip 绑定的网卡 （这里根据你自己的实际情况选择网卡）</span>
    interface eth0
    <span style="color:#6272a4"># 此ID 要与Backup 配置一致</span>
    virtual_router_id <span style="color:#bd93f9">51</span>
    <span style="color:#6272a4"># 默认启动优先级，要比Backup 大点，但要控制量，保证自身状态检测生效</span>
    priority <span style="color:#bd93f9">100</span>
    advert_int <span style="color:#bd93f9">1</span>
    authentication <span style="color:#ff79c6">{</span>
        auth_type PASS
        auth_pass <span style="color:#bd93f9">1111</span>
    <span style="color:#ff79c6">}</span>
    virtual_ipaddress <span style="color:#ff79c6">{</span>
        <span style="color:#6272a4"># 虚拟ip 地址</span>
        192.168.1.139
    <span style="color:#ff79c6">}</span>
    track_script <span style="color:#ff79c6">{</span>
        check_haproxy
    <span style="color:#ff79c6">}</span>
<span style="color:#ff79c6">}</span>

virtual_server 192.168.1.139 <span style="color:#bd93f9">80</span> <span style="color:#ff79c6">{</span>
  delay_loop <span style="color:#bd93f9">5</span>
  lvs_sched wlc
  lvs_method NAT
  persistence_timeout <span style="color:#bd93f9">1800</span>
  protocol TCP

  real_server 192.168.1.137 <span style="color:#bd93f9">80</span> <span style="color:#ff79c6">{</span>
    weight <span style="color:#bd93f9">1</span>
    TCP_CHECK <span style="color:#ff79c6">{</span>
      connect_port <span style="color:#bd93f9">80</span>
      connect_timeout <span style="color:#bd93f9">3</span>
    <span style="color:#ff79c6">}</span>
  <span style="color:#ff79c6">}</span>
<span style="color:#ff79c6">}</span>

virtual_server 192.168.1.139 <span style="color:#bd93f9">443</span> <span style="color:#ff79c6">{</span>
  delay_loop <span style="color:#bd93f9">5</span>
  lvs_sched wlc
  lvs_method NAT
  persistence_timeout <span style="color:#bd93f9">1800</span>
  protocol TCP

  real_server 192.168.1.137 <span style="color:#bd93f9">443</span> <span style="color:#ff79c6">{</span>
    weight <span style="color:#bd93f9">1</span>
    TCP_CHECK <span style="color:#ff79c6">{</span>
      connect_port <span style="color:#bd93f9">443</span>
      connect_timeout <span style="color:#bd93f9">3</span>
    <span style="color:#ff79c6">}</span>
  <span style="color:#ff79c6">}</span>
<span style="color:#ff79c6">}</span>

</code></pre></div><p>统一的方式在master02 节点上安装keepalived，修改配置，只需要将state 更改成BACKUP，priority更改成99，unicast_src_ip 与unicast_peer 地址修改即可。</p>
<p>启动keepalived:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ systemctl start keepalived
$ systemctl <span style="color:#8be9fd;font-style:italic">enable</span> keepalived
<span style="color:#6272a4"># 查看日志</span>
$ journalctl -f -u keepalived
</code></pre></div><p>验证虚拟IP:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#6272a4"># 使用ifconfig -a 命令查看不到，要使用ip addr</span>
$ ip addr
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span style="color:#bd93f9">65536</span> qdisc noqueue state UNKNOWN qlen <span style="color:#bd93f9">1</span>
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#bd93f9">1500</span> qdisc pfifo_fast state UP qlen <span style="color:#bd93f9">1000</span>
    link/ether 00:16:3e:00:55:c1 brd ff:ff:ff:ff:ff:ff
    inet 192.168.1.137/24 brd 192.168.1.255 scope global dynamic eth0
       valid_lft 31447746sec preferred_lft 31447746sec
    inet 192.168.1.139/24 brd 192.168.1.255 scope global secondary eth0-vip
       valid_lft forever preferred_lft forever
</code></pre></div><blockquote>
<p>到这里，我们就可以将上面的6443端口和8080端口去掉了，可以手动将<code>kubectl</code>生成的<code>config</code>文件(<code>~/.kube/config</code>)中的server 地址6443端口去掉，另外<code>kube-controller-manager</code>和<code>kube-scheduler</code>的**&ndash;master**参数中的8080端口去掉了，然后分别重启这两个组件即可。</p>
</blockquote>
<p>验证apiserver：关闭master01 节点上的kube-apiserver 进程，然后查看虚拟ip是否漂移到了master02 节点。</p>
<p>然后我们就可以将第一步在<code>/etc/hosts</code>里面设置的域名对应的IP 更改为我们的虚拟IP了</p>
<blockquote>
<p>master01 与master 02 节点都需要安装keepalived 和haproxy，实际上我们虚拟IP的自身检测应该是检测haproxy，脚本大家可以自行更改</p>
</blockquote>
<p>
  <img src="/img/posts/apiserver-ha.png" alt="kube-apiserver ha">

</p>
<p>这样我们就实现了接入层apiserver 的高可用了，一个部分是多活的apiserver 服务，另一个部分是一主一备的haproxy 服务。</p>
<h3 id="kube-controller-manager-和kube-scheduler-的高可用">kube-controller-manager 和kube-scheduler 的高可用</h3>
<p>Kubernetes 的管理层服务包括<code>kube-scheduler</code>和<code>kube-controller-manager</code>。kube-scheduler和kube-controller-manager使用一主多从的高可用方案，在<strong>同一时刻只允许一个服务</strong>处以具体的任务。Kubernetes中实现了一套简单的选主逻辑，依赖Etcd实现scheduler和controller-manager的选主功能。如果scheduler和controller-manager在启动的时候设置了<code>leader-elect</code>参数，它们在启动后会先尝试获取leader节点身份，只有在获取leader节点身份后才可以执行具体的业务逻辑。它们分别会在Etcd中创建kube-scheduler和kube-controller-manager的endpoint，endpoint的信息中记录了当前的leader节点信息，以及记录的上次更新时间。leader节点会定期更新endpoint的信息，维护自己的leader身份。每个从节点的服务都会定期检查endpoint的信息，如果endpoint的信息在时间范围内没有更新，它们会尝试更新自己为leader节点。scheduler服务以及controller-manager服务之间不会进行通信，利用Etcd的强一致性，能够保证在分布式高并发情况下leader节点的全局唯一性。整体方案如下图所示：</p>
<p>
  <img src="/img/posts/1498099870616.png" alt="img">

</p>
<p>当集群中的leader节点服务异常后，其它节点的服务会尝试更新自身为leader节点，当有多个节点同时更新endpoint时，由Etcd保证只有一个服务的更新请求能够成功。通过这种机制sheduler和controller-manager可以保证在leader节点宕机后其它的节点可以顺利选主，保证服务故障后快速恢复。当集群中的网络出现故障时对服务的选主影响不是很大，因为scheduler和controller-manager是依赖Etcd进行选主的，在网络故障后，可以和Etcd通信的主机依然可以按照之前的逻辑进行选主，就算集群被切分，Etcd也可以保证同一时刻只有一个节点的服务处于leader状态。</p>
<h2 id="8-部署node-节点a-idnodea">8. 部署Node 节点<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<p>kubernetes Node 节点包含如下组件：</p>
<ul>
<li>flanneld</li>
<li>docker</li>
<li>kubelet</li>
<li>kube-proxy</li>
</ul>
<h3 id="环境变量-3">环境变量</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ <span style="color:#8be9fd;font-style:italic">source</span> /usr/k8s/bin/env.sh
$ <span style="color:#8be9fd;font-style:italic">export</span> <span style="color:#8be9fd;font-style:italic">KUBE_APISERVER</span><span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;https://</span><span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">MASTER_URL</span><span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">&#34;</span>  // 如果你没有安装<span style="color:#f1fa8c">`</span>haproxy<span style="color:#f1fa8c">`</span>的话，还是需要使用6443端口的哦
$ <span style="color:#8be9fd;font-style:italic">export</span> <span style="color:#8be9fd;font-style:italic">NODE_IP</span><span style="color:#ff79c6">=</span>192.168.1.170  <span style="color:#6272a4"># 当前部署的节点 IP</span>
</code></pre></div><p>按照上面的步骤安装配置好flanneld</p>
<h3 id="开启路由转发">开启路由转发</h3>
<p>修改<code>/etc/sysctl.conf</code>文件，添加下面的规则：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">net.ipv4.ip_forward<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span>
net.bridge.bridge-nf-call-iptables<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span>
net.bridge.bridge-nf-call-ip6tables<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span>
</code></pre></div><p>执行下面的命令立即生效：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sysctl -p
</code></pre></div><h3 id="配置docker">配置docker</h3>
<p>你可以用二进制或yum install 的方式来安装docker，然后修改docker 的systemd unit 文件：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat /usr/lib/systemd/system/docker.service  <span style="color:#6272a4"># 用systemctl status docker 命令可查看unit 文件路径</span>
<span style="color:#ff79c6">[</span>Unit<span style="color:#ff79c6">]</span>
<span style="color:#8be9fd;font-style:italic">Description</span><span style="color:#ff79c6">=</span>Docker Application Container Engine
<span style="color:#8be9fd;font-style:italic">Documentation</span><span style="color:#ff79c6">=</span>https://docs.docker.com
<span style="color:#8be9fd;font-style:italic">After</span><span style="color:#ff79c6">=</span>network-online.target firewalld.service
<span style="color:#8be9fd;font-style:italic">Wants</span><span style="color:#ff79c6">=</span>network-online.target

<span style="color:#ff79c6">[</span>Service<span style="color:#ff79c6">]</span>
<span style="color:#8be9fd;font-style:italic">Type</span><span style="color:#ff79c6">=</span>notify
<span style="color:#6272a4"># the default is not to use systemd for cgroups because the delegate issues still</span>
<span style="color:#6272a4"># exists and systemd currently does not support the cgroup feature set required</span>
<span style="color:#6272a4"># for containers run by docker</span>
<span style="color:#8be9fd;font-style:italic">EnvironmentFile</span><span style="color:#ff79c6">=</span>-/run/flannel/docker
<span style="color:#8be9fd;font-style:italic">ExecStart</span><span style="color:#ff79c6">=</span>/usr/bin/dockerd --log-level<span style="color:#ff79c6">=</span>info <span style="color:#8be9fd;font-style:italic">$DOCKER_NETWORK_OPTIONS</span>
<span style="color:#8be9fd;font-style:italic">ExecReload</span><span style="color:#ff79c6">=</span>/bin/kill -s HUP <span style="color:#8be9fd;font-style:italic">$MAINPID</span>
<span style="color:#6272a4"># Having non-zero Limit*s causes performance problems due to accounting overhead</span>
<span style="color:#6272a4"># in the kernel. We recommend using cgroups to do container-local accounting.</span>
<span style="color:#8be9fd;font-style:italic">LimitNOFILE</span><span style="color:#ff79c6">=</span>infinity
<span style="color:#8be9fd;font-style:italic">LimitNPROC</span><span style="color:#ff79c6">=</span>infinity
<span style="color:#8be9fd;font-style:italic">LimitCORE</span><span style="color:#ff79c6">=</span>infinity
<span style="color:#6272a4"># Uncomment TasksMax if your systemd version supports it.</span>
<span style="color:#6272a4"># Only systemd 226 and above support this version.</span>
<span style="color:#6272a4">#TasksMax=infinity</span>
<span style="color:#8be9fd;font-style:italic">TimeoutStartSec</span><span style="color:#ff79c6">=</span><span style="color:#bd93f9">0</span>
<span style="color:#6272a4"># set delegate yes so that systemd does not reset the cgroups of docker containers</span>
<span style="color:#8be9fd;font-style:italic">Delegate</span><span style="color:#ff79c6">=</span>yes
<span style="color:#6272a4"># kill only the docker process, not all processes in the cgroup</span>
<span style="color:#8be9fd;font-style:italic">KillMode</span><span style="color:#ff79c6">=</span>process
<span style="color:#6272a4"># restart the docker process if it exits prematurely</span>
<span style="color:#8be9fd;font-style:italic">Restart</span><span style="color:#ff79c6">=</span>on-failure
<span style="color:#8be9fd;font-style:italic">StartLimitBurst</span><span style="color:#ff79c6">=</span><span style="color:#bd93f9">3</span>
<span style="color:#8be9fd;font-style:italic">StartLimitInterval</span><span style="color:#ff79c6">=</span>60s

<span style="color:#ff79c6">[</span>Install<span style="color:#ff79c6">]</span>
<span style="color:#8be9fd;font-style:italic">WantedBy</span><span style="color:#ff79c6">=</span>multi-user.target
</code></pre></div><ul>
<li>
<p>dockerd 运行时会调用其它 docker 命令，如 docker-proxy，所以需要将 docker 命令所在的目录加到 PATH 环境变量中</p>
</li>
<li>
<p>flanneld 启动时将网络配置写入到 <code>/run/flannel/docker</code> 文件中的变量 <code>DOCKER_NETWORK_OPTIONS</code>，dockerd 命令行上指定该变量值来设置 docker0 网桥参数</p>
</li>
<li>
<p>如果指定了多个 <code>EnvironmentFile</code> 选项，则必须将 <code>/run/flannel/docker</code> 放在最后(确保 docker0 使用 flanneld 生成的 bip 参数)</p>
</li>
<li>
<p>不能关闭默认开启的 <code>--iptables</code> 和 <code>--ip-masq</code> 选项</p>
</li>
<li>
<p>如果内核版本比较新，建议使用 <code>overlay</code> 存储驱动</p>
</li>
<li>
<p>docker 从 1.13 版本开始，可能将 <strong>iptables FORWARD chain的默认策略设置为DROP</strong>，从而导致 ping 其它 Node 上的 Pod IP 失败，遇到这种情况时，需要手动设置策略为 <code>ACCEPT</code>：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo iptables -P FORWARD ACCEPT
</code></pre></div><p>如果没有开启上面的路由转发(<code>net.ipv4.ip_forward=1</code>)，则需要把以下命令写入<code>/etc/rc.local</code>文件中，防止节点重启<strong>iptables FORWARD chain的默认策略又还原为DROP</strong>（下面的开机脚本我测试了几次都没生效，不知道是不是方法有误，所以最好的方式还是开启上面的路由转发功能，一劳永逸）</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">sleep <span style="color:#bd93f9">60</span> <span style="color:#ff79c6">&amp;&amp;</span> /sbin/iptables -P FORWARD ACCEPT
</code></pre></div></li>
<li>
<p>为了加快 pull image 的速度，可以使用国内的仓库镜像服务器，同时增加下载的并发数。(如果 dockerd 已经运行，则需要重启 dockerd 生效。)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat /etc/docker/daemon.json
<span style="color:#ff79c6">{</span>
  <span style="color:#f1fa8c">&#34;max-concurrent-downloads&#34;</span>: <span style="color:#bd93f9">10</span>
<span style="color:#ff79c6">}</span>
</code></pre></div></li>
</ul>
<h3 id="启动docker">启动docker</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo systemctl daemon-reload
$ sudo systemctl stop firewalld
$ sudo systemctl disable firewalld
$ sudo iptables -F <span style="color:#ff79c6">&amp;&amp;</span> sudo iptables -X <span style="color:#ff79c6">&amp;&amp;</span> sudo iptables -F -t nat <span style="color:#ff79c6">&amp;&amp;</span> sudo iptables -X -t nat
$ sudo systemctl <span style="color:#8be9fd;font-style:italic">enable</span> docker
$ sudo systemctl start docker
</code></pre></div><ul>
<li>需要关闭 firewalld(centos7)/ufw(ubuntu16.04)，否则可能会重复创建 iptables 规则</li>
<li>最好清理旧的 iptables rules 和 chains 规则</li>
<li>执行命令：docker version，检查docker服务是否正常</li>
</ul>
<h3 id="安装和配置kubelet">安装和配置kubelet</h3>
<p>kubelet 启动时向kube-apiserver 发送TLS bootstrapping 请求，需要先将bootstrap token 文件中的kubelet-bootstrap 用户赋予system:node-bootstrapper 角色，然后kubelet 才有权限创建认证请求(certificatesigningrequests)：</p>
<blockquote>
<p>kubelet就是运行在Node节点上的，所以这一步安装是在所有的Node节点上，如果你想把你的Master也当做Node节点的话，当然也可以在Master节点上安装的。</p>
</blockquote>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl create clusterrolebinding kubelet-bootstrap --clusterrole<span style="color:#ff79c6">=</span>system:node-bootstrapper --user<span style="color:#ff79c6">=</span>kubelet-bootstrap
</code></pre></div><ul>
<li><code>--user=kubelet-bootstrap</code> 是文件 <code>/etc/kubernetes/token.csv</code> 中指定的用户名，同时也写入了文件 <code>/etc/kubernetes/bootstrap.kubeconfig</code></li>
</ul>
<p>另外1.8 版本中还需要为Node 请求创建一个RBAC 授权规则：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl create clusterrolebinding kubelet-nodes --clusterrole<span style="color:#ff79c6">=</span>system:node --group<span style="color:#ff79c6">=</span>system:nodes
</code></pre></div><p>然后下载最新的kubelet 和kube-proxy 二进制文件（前面下载kubernetes 目录下面其实也有）：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ wget https://dl.k8s.io/v1.8.2/kubernetes-server-linux-amd64.tar.gz
$ tar -xzvf kubernetes-server-linux-amd64.tar.gz
$ <span style="color:#8be9fd;font-style:italic">cd</span> kubernetes
$ tar -xzvf  kubernetes-src.tar.gz
$ sudo cp -r ./server/bin/<span style="color:#ff79c6">{</span>kube-proxy,kubelet<span style="color:#ff79c6">}</span> /usr/k8s/bin/
</code></pre></div><h3 id="创建kubelet-bootstapping-kubeconfig-文件">创建kubelet bootstapping kubeconfig 文件</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ <span style="color:#6272a4"># 设置集群参数</span>
$ kubectl config set-cluster kubernetes <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --certificate-authority<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --embed-certs<span style="color:#ff79c6">=</span><span style="color:#8be9fd;font-style:italic">true</span> <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --server<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">KUBE_APISERVER</span><span style="color:#f1fa8c">}</span> <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --kubeconfig<span style="color:#ff79c6">=</span>bootstrap.kubeconfig
$ <span style="color:#6272a4"># 设置客户端认证参数</span>
$ kubectl config set-credentials kubelet-bootstrap <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --token<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">BOOTSTRAP_TOKEN</span><span style="color:#f1fa8c">}</span> <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --kubeconfig<span style="color:#ff79c6">=</span>bootstrap.kubeconfig
$ <span style="color:#6272a4"># 设置上下文参数</span>
$ kubectl config set-context default <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --cluster<span style="color:#ff79c6">=</span>kubernetes <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --user<span style="color:#ff79c6">=</span>kubelet-bootstrap <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --kubeconfig<span style="color:#ff79c6">=</span>bootstrap.kubeconfig
$ <span style="color:#6272a4"># 设置默认上下文</span>
$ kubectl config use-context default --kubeconfig<span style="color:#ff79c6">=</span>bootstrap.kubeconfig
$ mv bootstrap.kubeconfig /etc/kubernetes/
</code></pre></div><ul>
<li><code>--embed-certs</code> 为 <code>true</code> 时表示将 <code>certificate-authority</code> 证书写入到生成的 <code>bootstrap.kubeconfig</code> 文件中；</li>
<li>设置 kubelet 客户端认证参数时<strong>没有</strong>指定秘钥和证书，后续由 <code>kube-apiserver</code> 自动生成；</li>
</ul>
<h3 id="创建kubelet-的systemd-unit-文件">创建kubelet 的systemd unit 文件</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo mkdir /var/lib/kubelet <span style="color:#6272a4"># 必须先创建工作目录</span>
$ cat &gt; kubelet.service <span style="color:#f1fa8c">&lt;&lt;EOF
</span><span style="color:#f1fa8c">[Unit]
</span><span style="color:#f1fa8c">Description=Kubernetes Kubelet
</span><span style="color:#f1fa8c">Documentation=https://github.com/GoogleCloudPlatform/kubernetes
</span><span style="color:#f1fa8c">After=docker.service
</span><span style="color:#f1fa8c">Requires=docker.service
</span><span style="color:#f1fa8c">
</span><span style="color:#f1fa8c">[Service]
</span><span style="color:#f1fa8c">WorkingDirectory=/var/lib/kubelet
</span><span style="color:#f1fa8c">ExecStart=/usr/k8s/bin/kubelet \\
</span><span style="color:#f1fa8c">  --fail-swap-on=false \\
</span><span style="color:#f1fa8c">  --cgroup-driver=cgroupfs \\
</span><span style="color:#f1fa8c">  --address=${NODE_IP} \\
</span><span style="color:#f1fa8c">  --hostname-override=${NODE_IP} \\
</span><span style="color:#f1fa8c">  --experimental-bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \\
</span><span style="color:#f1fa8c">  --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\
</span><span style="color:#f1fa8c">  --require-kubeconfig \\
</span><span style="color:#f1fa8c">  --cert-dir=/etc/kubernetes/ssl \\
</span><span style="color:#f1fa8c">  --cluster-dns=${CLUSTER_DNS_SVC_IP} \\
</span><span style="color:#f1fa8c">  --cluster-domain=${CLUSTER_DNS_DOMAIN} \\
</span><span style="color:#f1fa8c">  --hairpin-mode promiscuous-bridge \\
</span><span style="color:#f1fa8c">  --allow-privileged=true \\
</span><span style="color:#f1fa8c">  --serialize-image-pulls=false \\
</span><span style="color:#f1fa8c">  --logtostderr=true \\
</span><span style="color:#f1fa8c">  --v=2
</span><span style="color:#f1fa8c">Restart=on-failure
</span><span style="color:#f1fa8c">RestartSec=5
</span><span style="color:#f1fa8c">
</span><span style="color:#f1fa8c">[Install]
</span><span style="color:#f1fa8c">WantedBy=multi-user.target
</span><span style="color:#f1fa8c">EOF</span>
</code></pre></div><blockquote>
<p><strong>请仔细阅读下面的注意事项，不然可能会启动失败</strong>。</p>
</blockquote>
<ul>
<li><code>--fail-swap-on</code>参数，这个一定要注意，<strong>Kubernetes 1.8开始要求关闭系统的Swap</strong>，如果不关闭，默认配置下kubelet将无法启动，也可以通过kubelet的启动参数<code>–fail-swap-on=false</code>来避免该问题</li>
<li><code>--cgroup-driver</code>参数，kubelet 用来维护主机的的 cgroups 的，默认是<code>cgroupfs</code>，但是这个地方的值需要你根据docker 的配置来确定（<code>docker info |grep cgroup</code>）</li>
<li><code>-address</code> 不能设置为 <code>127.0.0.1</code>，否则后续 Pods 访问 kubelet 的 API 接口时会失败，因为 Pods 访问的 <code>127.0.0.1</code>指向自己而不是 kubelet</li>
<li>如果设置了 <code>--hostname-override</code> 选项，则 <code>kube-proxy</code> 也需要设置该选项，否则会出现找不到 Node 的情况</li>
<li><code>--experimental-bootstrap-kubeconfig</code> 指向 bootstrap kubeconfig 文件，kubelet 使用该文件中的用户名和 token 向 kube-apiserver 发送 TLS Bootstrapping 请求</li>
<li>管理员通过了 CSR 请求后，kubelet 自动在 <code>--cert-dir</code> 目录创建证书和私钥文件(<code>kubelet-client.crt</code> 和 <code>kubelet-client.key</code>)，然后写入 <code>--kubeconfig</code> 文件(自动创建 <code>--kubeconfig</code> 指定的文件)</li>
<li>建议在 <code>--kubeconfig</code> 配置文件中指定 <code>kube-apiserver</code> 地址，如果未指定 <code>--api-servers</code> 选项，则必须指定 <code>--require-kubeconfig</code> 选项后才从配置文件中读取 kue-apiserver 的地址，否则 kubelet 启动后将找不到 kube-apiserver (日志中提示未找到 API Server），<code>kubectl get nodes</code> 不会返回对应的 Node 信息</li>
<li><code>--cluster-dns</code> 指定 kubedns 的 Service IP(可以先分配，后续创建 kubedns 服务时指定该 IP)，<code>--cluster-domain</code> 指定域名后缀，这两个参数同时指定后才会生效</li>
</ul>
<h3 id="启动kubelet">启动kubelet</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo cp kubelet.service /etc/systemd/system/kubelet.service
$ sudo systemctl daemon-reload
$ sudo systemctl <span style="color:#8be9fd;font-style:italic">enable</span> kubelet
$ sudo systemctl start kubelet
$ systemctl status kubelet
</code></pre></div><h3 id="通过kubelet-的tls-证书请求">通过kubelet 的TLS 证书请求</h3>
<p>kubelet 首次启动时向kube-apiserver 发送证书签名请求，必须通过后kubernetes 系统才会将该 Node 加入到集群。查看未授权的CSR 请求：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl get csr
NAME                                                   AGE       REQUESTOR           CONDITION
node-csr--k3G2G1EoM4h9w1FuJRjJjfbIPNxa551A8TZfW9dG-g   2m        kubelet-bootstrap   Pending
$ kubectl get nodes
No resources found.
</code></pre></div><p>通过CSR 请求：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl certificate approve node-csr--k3G2G1EoM4h9w1FuJRjJjfbIPNxa551A8TZfW9dG-g
certificatesigningrequest <span style="color:#f1fa8c">&#34;node-csr--k3G2G1EoM4h9w1FuJRjJjfbIPNxa551A8TZfW9dG-g&#34;</span> approved
$ kubectl get nodes
NAME            STATUS    ROLES     AGE       VERSION
192.168.1.170   Ready     &lt;none&gt;    48s       v1.8.1
</code></pre></div><p>自动生成了kubelet kubeconfig 文件和公私钥：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ ls -l /etc/kubernetes/kubelet.kubeconfig
-rw------- <span style="color:#bd93f9">1</span> root root <span style="color:#bd93f9">2280</span> Nov  <span style="color:#bd93f9">7</span> 10:26 /etc/kubernetes/kubelet.kubeconfig
$ ls -l /etc/kubernetes/ssl/kubelet*
-rw-r--r-- <span style="color:#bd93f9">1</span> root root <span style="color:#bd93f9">1046</span> Nov  <span style="color:#bd93f9">7</span> 10:26 /etc/kubernetes/ssl/kubelet-client.crt
-rw------- <span style="color:#bd93f9">1</span> root root  <span style="color:#bd93f9">227</span> Nov  <span style="color:#bd93f9">7</span> 10:22 /etc/kubernetes/ssl/kubelet-client.key
-rw-r--r-- <span style="color:#bd93f9">1</span> root root <span style="color:#bd93f9">1115</span> Nov  <span style="color:#bd93f9">7</span> 10:16 /etc/kubernetes/ssl/kubelet.crt
-rw------- <span style="color:#bd93f9">1</span> root root <span style="color:#bd93f9">1675</span> Nov  <span style="color:#bd93f9">7</span> 10:16 /etc/kubernetes/ssl/kubelet.key
</code></pre></div><h3 id="配置kube-proxy">配置kube-proxy</h3>
<h4 id="创建kube-proxy-证书签名请求">创建kube-proxy 证书签名请求：</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat &gt; kube-proxy-csr.json <span style="color:#f1fa8c">&lt;&lt;EOF
</span><span style="color:#f1fa8c">{
</span><span style="color:#f1fa8c">  &#34;CN&#34;: &#34;system:kube-proxy&#34;,
</span><span style="color:#f1fa8c">  &#34;hosts&#34;: [],
</span><span style="color:#f1fa8c">  &#34;key&#34;: {
</span><span style="color:#f1fa8c">    &#34;algo&#34;: &#34;rsa&#34;,
</span><span style="color:#f1fa8c">    &#34;size&#34;: 2048
</span><span style="color:#f1fa8c">  },
</span><span style="color:#f1fa8c">  &#34;names&#34;: [
</span><span style="color:#f1fa8c">    {
</span><span style="color:#f1fa8c">      &#34;C&#34;: &#34;CN&#34;,
</span><span style="color:#f1fa8c">      &#34;ST&#34;: &#34;BeiJing&#34;,
</span><span style="color:#f1fa8c">      &#34;L&#34;: &#34;BeiJing&#34;,
</span><span style="color:#f1fa8c">      &#34;O&#34;: &#34;k8s&#34;,
</span><span style="color:#f1fa8c">      &#34;OU&#34;: &#34;System&#34;
</span><span style="color:#f1fa8c">    }
</span><span style="color:#f1fa8c">  ]
</span><span style="color:#f1fa8c">}
</span><span style="color:#f1fa8c">EOF</span>
</code></pre></div><ul>
<li>CN 指定该证书的 User 为 <code>system:kube-proxy</code></li>
<li><code>kube-apiserver</code> 预定义的 RoleBinding <code>system:node-proxier</code> 将User <code>system:kube-proxy</code> 与 Role <code>system:node-proxier</code>绑定，该 Role 授予了调用 <code>kube-apiserver</code> Proxy 相关 API 的权限</li>
<li>hosts 属性值为空列表</li>
</ul>
<h4 id="生成kube-proxy-客户端证书和私钥">生成kube-proxy 客户端证书和私钥</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cfssl gencert -ca<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  -ca-key<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca-key.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  -config<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca-config.json <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  -profile<span style="color:#ff79c6">=</span>kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy
$ ls kube-proxy*
kube-proxy.csr  kube-proxy-csr.json  kube-proxy-key.pem  kube-proxy.pem
$ sudo mv kube-proxy*.pem /etc/kubernetes/ssl/
</code></pre></div><h4 id="创建kube-proxy-kubeconfig-文件">创建kube-proxy kubeconfig 文件</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ <span style="color:#6272a4"># 设置集群参数</span>
$ kubectl config set-cluster kubernetes <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --certificate-authority<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/ca.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --embed-certs<span style="color:#ff79c6">=</span><span style="color:#8be9fd;font-style:italic">true</span> <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --server<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">${</span><span style="color:#8be9fd;font-style:italic">KUBE_APISERVER</span><span style="color:#f1fa8c">}</span> <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --kubeconfig<span style="color:#ff79c6">=</span>kube-proxy.kubeconfig
$ <span style="color:#6272a4"># 设置客户端认证参数</span>
$ kubectl config set-credentials kube-proxy <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --client-certificate<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/kube-proxy.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --client-key<span style="color:#ff79c6">=</span>/etc/kubernetes/ssl/kube-proxy-key.pem <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --embed-certs<span style="color:#ff79c6">=</span><span style="color:#8be9fd;font-style:italic">true</span> <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --kubeconfig<span style="color:#ff79c6">=</span>kube-proxy.kubeconfig
$ <span style="color:#6272a4"># 设置上下文参数</span>
$ kubectl config set-context default <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --cluster<span style="color:#ff79c6">=</span>kubernetes <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --user<span style="color:#ff79c6">=</span>kube-proxy <span style="color:#f1fa8c">\
</span><span style="color:#f1fa8c"></span>  --kubeconfig<span style="color:#ff79c6">=</span>kube-proxy.kubeconfig
$ <span style="color:#6272a4"># 设置默认上下文</span>
$ kubectl config use-context default --kubeconfig<span style="color:#ff79c6">=</span>kube-proxy.kubeconfig
$ mv kube-proxy.kubeconfig /etc/kubernetes/
</code></pre></div><ul>
<li>设置集群参数和客户端认证参数时 <code>--embed-certs</code> 都为 <code>true</code>，这会将 <code>certificate-authority</code>、<code>client-certificate</code> 和 <code>client-key</code> 指向的证书文件内容写入到生成的 <code>kube-proxy.kubeconfig</code> 文件中</li>
<li><code>kube-proxy.pem</code> 证书中 CN 为 <code>system:kube-proxy</code>，<code>kube-apiserver</code> 预定义的 RoleBinding <code>cluster-admin</code> 将User <code>system:kube-proxy</code> 与 Role <code>system:node-proxier</code> 绑定，该 Role 授予了调用 <code>kube-apiserver</code> Proxy 相关 API 的权限</li>
</ul>
<h4 id="创建kube-proxy-的systemd-unit-文件">创建kube-proxy 的systemd unit 文件</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo mkdir -p /var/lib/kube-proxy <span style="color:#6272a4"># 必须先创建工作目录</span>
$ cat &gt; kube-proxy.service <span style="color:#f1fa8c">&lt;&lt;EOF
</span><span style="color:#f1fa8c">[Unit]
</span><span style="color:#f1fa8c">Description=Kubernetes Kube-Proxy Server
</span><span style="color:#f1fa8c">Documentation=https://github.com/GoogleCloudPlatform/kubernetes
</span><span style="color:#f1fa8c">After=network.target
</span><span style="color:#f1fa8c">
</span><span style="color:#f1fa8c">[Service]
</span><span style="color:#f1fa8c">WorkingDirectory=/var/lib/kube-proxy
</span><span style="color:#f1fa8c">ExecStart=/usr/k8s/bin/kube-proxy \\
</span><span style="color:#f1fa8c">  --bind-address=${NODE_IP} \\
</span><span style="color:#f1fa8c">  --hostname-override=${NODE_IP} \\
</span><span style="color:#f1fa8c">  --cluster-cidr=${SERVICE_CIDR} \\
</span><span style="color:#f1fa8c">  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig \\
</span><span style="color:#f1fa8c">  --logtostderr=true \\
</span><span style="color:#f1fa8c">  --v=2
</span><span style="color:#f1fa8c">Restart=on-failure
</span><span style="color:#f1fa8c">RestartSec=5
</span><span style="color:#f1fa8c">LimitNOFILE=65536
</span><span style="color:#f1fa8c">
</span><span style="color:#f1fa8c">[Install]
</span><span style="color:#f1fa8c">WantedBy=multi-user.target
</span><span style="color:#f1fa8c">EOF</span>
</code></pre></div><ul>
<li><code>--hostname-override</code> 参数值必须与 kubelet 的值一致，否则 kube-proxy 启动后会找不到该 Node，从而不会创建任何 iptables 规则</li>
<li><code>--cluster-cidr</code> 必须与 kube-apiserver 的 <code>--service-cluster-ip-range</code> 选项值一致</li>
<li>kube-proxy 根据 <code>--cluster-cidr</code> 判断集群内部和外部流量，指定 <code>--cluster-cidr</code> 或 <code>--masquerade-all</code> 选项后 kube-proxy 才会对访问 Service IP 的请求做 SNAT</li>
<li><code>--kubeconfig</code> 指定的配置文件嵌入了 kube-apiserver 的地址、用户名、证书、秘钥等请求和认证信息</li>
<li>预定义的 RoleBinding <code>cluster-admin</code> 将User <code>system:kube-proxy</code> 与 Role <code>system:node-proxier</code> 绑定，该 Role 授予了调用 <code>kube-apiserver</code> Proxy 相关 API 的权限</li>
</ul>
<h4 id="启动kube-proxy">启动kube-proxy</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ sudo cp kube-proxy.service /etc/systemd/system/
$ sudo systemctl daemon-reload
$ sudo systemctl <span style="color:#8be9fd;font-style:italic">enable</span> kube-proxy
$ sudo systemctl start kube-proxy
$ systemctl status kube-proxy
</code></pre></div><h3 id="验证集群功能">验证集群功能</h3>
<p>定义yaml 文件：（将下面内容保存为：nginx-ds.yaml）</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#ff79c6">apiVersion</span>: v1
<span style="color:#ff79c6">kind</span>: Service
<span style="color:#ff79c6">metadata</span>:
  <span style="color:#ff79c6">name</span>: nginx-ds
  <span style="color:#ff79c6">labels</span>:
    <span style="color:#ff79c6">app</span>: nginx-ds
<span style="color:#ff79c6">spec</span>:
  <span style="color:#ff79c6">type</span>: NodePort
  <span style="color:#ff79c6">selector</span>:
    <span style="color:#ff79c6">app</span>: nginx-ds
  <span style="color:#ff79c6">ports</span>:
  - <span style="color:#ff79c6">name</span>: http
    <span style="color:#ff79c6">port</span>: <span style="color:#bd93f9">80</span>
    <span style="color:#ff79c6">targetPort</span>: <span style="color:#bd93f9">80</span>
---
<span style="color:#ff79c6">apiVersion</span>: extensions/v1beta1
<span style="color:#ff79c6">kind</span>: DaemonSet
<span style="color:#ff79c6">metadata</span>:
  <span style="color:#ff79c6">name</span>: nginx-ds
  <span style="color:#ff79c6">labels</span>:
    <span style="color:#ff79c6">addonmanager.kubernetes.io/mode</span>: Reconcile
<span style="color:#ff79c6">spec</span>:
  <span style="color:#ff79c6">template</span>:
    <span style="color:#ff79c6">metadata</span>:
      <span style="color:#ff79c6">labels</span>:
        <span style="color:#ff79c6">app</span>: nginx-ds
    <span style="color:#ff79c6">spec</span>:
      <span style="color:#ff79c6">containers</span>:
      - <span style="color:#ff79c6">name</span>: my-nginx
        <span style="color:#ff79c6">image</span>: nginx:1.7.9
        <span style="color:#ff79c6">ports</span>:
        - <span style="color:#ff79c6">containerPort</span>: <span style="color:#bd93f9">80</span>
</code></pre></div><p>创建 Pod 和服务：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl create -f nginx-ds.yml
service <span style="color:#f1fa8c">&#34;nginx-ds&#34;</span> created
daemonset <span style="color:#f1fa8c">&#34;nginx-ds&#34;</span> created
</code></pre></div><p>执行下面的命令查看Pod 和SVC：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl get pods -o wide
NAME             READY     STATUS    RESTARTS   AGE       IP           NODE
nginx-ds-f29zt   1/1       Running   <span style="color:#bd93f9">0</span>          23m       172.17.0.2   192.168.1.170
$ kubectl get svc
NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT<span style="color:#ff79c6">(</span>S<span style="color:#ff79c6">)</span>        AGE
nginx-ds     NodePort    10.254.6.249   &lt;none&gt;        80:30813/TCP   24m
</code></pre></div><p>可以看到：</p>
<ul>
<li>服务IP：10.254.6.249</li>
<li>服务端口：80</li>
<li>NodePort端口：30813</li>
</ul>
<p>在所有 Node 上执行：</p>
<pre><code>$ curl 10.254.6.249
$ curl 192.168.1.170:30813
</code></pre><p>执行上面的命令预期都会输出nginx 欢迎页面内容，表示我们的Node 节点正常运行了。</p>
<h2 id="9-部署kubedns-插件a-idkubednsa">9. 部署kubedns 插件<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<p>官方文件目录：<a href="https://github.com/kubernetes/kubernetes/tree/v1.8.2/cluster/addons/dns">kubernetes/cluster/addons/dns</a></p>
<p>使用的文件：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ ls *.yaml *.base
kubedns-cm.yaml  kubedns-sa.yaml  kubedns-controller.yaml.base  kubedns-svc.yaml.base
</code></pre></div><h3 id="系统预定义的rolebinding">系统预定义的RoleBinding</h3>
<p>预定义的RoleBinding <code>system:kube-dns</code>将kube-system 命名空间的<code>kube-dns</code>ServiceAccount 与 <code>system:kube-dns</code> Role 绑定，该Role 具有访问kube-apiserver DNS 相关的API 权限：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl get clusterrolebindings system:kube-dns -o yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: <span style="color:#f1fa8c">&#34;true&#34;</span>
  creationTimestamp: 2017-11-06T10:51:59Z
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:kube-dns
  resourceVersion: <span style="color:#f1fa8c">&#34;78&#34;</span>
  selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Akube-dns
  uid: 83a25fd9-c2e0-11e7-9646-00163e0055c1
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:kube-dns
subjects:
- kind: ServiceAccount
  name: kube-dns
  namespace: kube-system
</code></pre></div><ul>
<li><code>kubedns-controller.yaml</code> 中定义的 Pods 时使用了 <code>kubedns-sa.yaml</code> 文件定义的 <code>kube-dns</code> ServiceAccount，所以具有访问 kube-apiserver DNS 相关 API 的权限；</li>
</ul>
<h3 id="配置kube-dns-serviceaccount">配置kube-dns ServiceAccount</h3>
<p>无需更改</p>
<h3 id="配置kube-dns-服务">配置kube-dns 服务</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ diff kubedns-svc.yaml.base kubedns-svc.yaml
30c30
&lt;   clusterIP: __PILLAR__DNS__SERVER__
---
&gt;   clusterIP: 10.254.0.2
</code></pre></div><ul>
<li>需要将 spec.clusterIP 设置为集群环境变量中变量 <code>CLUSTER_DNS_SVC_IP</code> 值，这个IP 需要和 kubelet 的 <code>—cluster-dns</code> 参数值一致</li>
</ul>
<h3 id="配置kube-dns-deployment">配置kube-dns Deployment</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ diff kubedns-controller.yaml.base kubedns-controller.yaml
88c88
&lt;         - --domain<span style="color:#ff79c6">=</span>__PILLAR__DNS__DOMAIN__.
---
&gt;         - --domain<span style="color:#ff79c6">=</span>cluster.local
128c128
&lt;         - --server<span style="color:#ff79c6">=</span>/__PILLAR__DNS__DOMAIN__/127.0.0.1#10053
---
&gt;         - --server<span style="color:#ff79c6">=</span>/cluster.local/127.0.0.1#10053
160,161c160,161
&lt;         - --probe<span style="color:#ff79c6">=</span>kubedns,127.0.0.1:10053,kubernetes.default.svc.__PILLAR__DNS__DOMAIN__,5,A
&lt;         - --probe<span style="color:#ff79c6">=</span>dnsmasq,127.0.0.1:53,kubernetes.default.svc.__PILLAR__DNS__DOMAIN__,5,A
---
&gt;         - --probe<span style="color:#ff79c6">=</span>kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,A
&gt;         - --probe<span style="color:#ff79c6">=</span>dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,A
</code></pre></div><ul>
<li><code>--domain</code> 为集群环境变量<code>CLUSTER_DNS_DOMAIN</code> 的值</li>
<li>使用系统已经做了 RoleBinding 的 <code>kube-dns</code> ServiceAccount，该账户具有访问 kube-apiserver DNS 相关 API 的权限</li>
</ul>
<h3 id="执行所有定义文件">执行所有定义文件</h3>
<pre><code>$ pwd
/home/ych/k8s-repo/kube-dns
$ ls *.yaml
kubedns-cm.yaml  kubedns-controller.yaml  kubedns-sa.yaml  kubedns-svc.yaml
$ kubectl create -f .
</code></pre><h3 id="检查kubedns-功能">检查kubedns 功能</h3>
<p>新建一个Deployment</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat &gt; my-nginx.yaml<span style="color:#f1fa8c">&lt;&lt;EOF
</span><span style="color:#f1fa8c">apiVersion: extensions/v1beta1
</span><span style="color:#f1fa8c">kind: Deployment
</span><span style="color:#f1fa8c">metadata:
</span><span style="color:#f1fa8c">  name: my-nginx
</span><span style="color:#f1fa8c">spec:
</span><span style="color:#f1fa8c">  replicas: 2
</span><span style="color:#f1fa8c">  template:
</span><span style="color:#f1fa8c">    metadata:
</span><span style="color:#f1fa8c">      labels:
</span><span style="color:#f1fa8c">        run: my-nginx
</span><span style="color:#f1fa8c">    spec:
</span><span style="color:#f1fa8c">      containers:
</span><span style="color:#f1fa8c">      - name: my-nginx
</span><span style="color:#f1fa8c">        image: nginx:1.7.9
</span><span style="color:#f1fa8c">        ports:
</span><span style="color:#f1fa8c">        - containerPort: 80
</span><span style="color:#f1fa8c">EOF</span>
$ kubectl create -f my-nginx.yaml
deployment <span style="color:#f1fa8c">&#34;my-nginx&#34;</span> created
</code></pre></div><p>Expose 该Deployment，生成my-nginx 服务</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl expose deploy my-nginx
$ kubectl get services
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT<span style="color:#ff79c6">(</span>S<span style="color:#ff79c6">)</span>   AGE
kubernetes   ClusterIP   10.254.0.1      &lt;none&gt;        443/TCP   1d
my-nginx     ClusterIP   10.254.32.162   &lt;none&gt;        80/TCP    56s
</code></pre></div><p>然后创建另外一个Pod，查看<code>/etc/resolv.conf</code>是否包含<code>kubelet</code>配置的<code>--cluster-dns</code> 和<code>--cluster-domain</code>，是否能够将服务<code>my-nginx</code> 解析到上面显示的CLUSTER-IP <code>10.254.32.162</code>上</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat &gt; pod-nginx.yaml<span style="color:#f1fa8c">&lt;&lt;EOF
</span><span style="color:#f1fa8c">apiVersion: v1
</span><span style="color:#f1fa8c">kind: Pod
</span><span style="color:#f1fa8c">metadata:
</span><span style="color:#f1fa8c">  name: nginx
</span><span style="color:#f1fa8c">spec:
</span><span style="color:#f1fa8c">  containers:
</span><span style="color:#f1fa8c">  - name: nginx
</span><span style="color:#f1fa8c">    image: nginx:1.7.9
</span><span style="color:#f1fa8c">    ports:
</span><span style="color:#f1fa8c">    - containerPort: 80
</span><span style="color:#f1fa8c">EOF</span>
$ kubectl create -f pod-nginx.yaml
pod <span style="color:#f1fa8c">&#34;nginx&#34;</span> created
$ kubectl <span style="color:#8be9fd;font-style:italic">exec</span>  nginx -i -t -- /bin/bash
root@nginx:/# cat /etc/resolv.conf
nameserver 10.254.0.2
search default.svc.cluster.local. svc.cluster.local. cluster.local.
options ndots:5
root@nginx:/# ping my-nginx
PING my-nginx.default.svc.cluster.local <span style="color:#ff79c6">(</span>10.254.32.162<span style="color:#ff79c6">)</span>: <span style="color:#bd93f9">48</span> data bytes
^C--- my-nginx.default.svc.cluster.local ping statistics ---
<span style="color:#bd93f9">14</span> packets transmitted, <span style="color:#bd93f9">0</span> packets received, 100% packet loss

root@nginx:/# ping kubernetes
PING kubernetes.default.svc.cluster.local <span style="color:#ff79c6">(</span>10.254.0.1<span style="color:#ff79c6">)</span>: <span style="color:#bd93f9">48</span> data bytes
^C--- kubernetes.default.svc.cluster.local ping statistics ---
<span style="color:#bd93f9">6</span> packets transmitted, <span style="color:#bd93f9">0</span> packets received, 100% packet loss

root@nginx:/# ping kube-dns.kube-system.svc.cluster.local
PING kube-dns.kube-system.svc.cluster.local <span style="color:#ff79c6">(</span>10.254.0.2<span style="color:#ff79c6">)</span>: <span style="color:#bd93f9">48</span> data bytes
^C--- kube-dns.kube-system.svc.cluster.local ping statistics ---
<span style="color:#bd93f9">2</span> packets transmitted, <span style="color:#bd93f9">0</span> packets received, 100% packet loss
</code></pre></div><h2 id="10-部署dashboard-插件a-iddashboarda">10. 部署Dashboard 插件<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<p>官方文件目录：<a href="https://github.com/kubernetes/kubernetes/tree/v1.8.2/cluster/addons/dashboard">kubernetes/cluster/addons/dashboard</a></p>
<p>使用的文件如下：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ ls *.yaml
dashboard-controller.yaml  dashboard-rbac.yaml  dashboard-service.yaml
</code></pre></div><ul>
<li>新加了 <code>dashboard-rbac.yaml</code> 文件，定义 dashboard 使用的 RoleBinding。</li>
</ul>
<p>由于 <code>kube-apiserver</code> 启用了 <code>RBAC</code> 授权，而官方源码目录的 <code>dashboard-controller.yaml</code> 没有定义授权的 ServiceAccount，所以后续访问 <code>kube-apiserver</code> 的 API 时会被拒绝，前端界面提示：</p>
<p>
  <img src="/img/posts/dashboard-403.png" alt="403">

</p>
<p>解决办法是：定义一个名为dashboard 的ServiceAccount，然后将它和Cluster Role view 绑定：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat &gt; dashboard-rbac.yaml<span style="color:#f1fa8c">&lt;&lt;EOF
</span><span style="color:#f1fa8c">apiVersion: v1
</span><span style="color:#f1fa8c">kind: ServiceAccount
</span><span style="color:#f1fa8c">metadata:
</span><span style="color:#f1fa8c">  name: dashboard
</span><span style="color:#f1fa8c">  namespace: kube-system
</span><span style="color:#f1fa8c">---
</span><span style="color:#f1fa8c">kind: ClusterRoleBinding
</span><span style="color:#f1fa8c">apiVersion: rbac.authorization.k8s.io/v1alpha1
</span><span style="color:#f1fa8c">metadata:
</span><span style="color:#f1fa8c">  name: dashboard
</span><span style="color:#f1fa8c">subjects:
</span><span style="color:#f1fa8c">  - kind: ServiceAccount
</span><span style="color:#f1fa8c">    name: dashboard
</span><span style="color:#f1fa8c">    namespace: kube-system
</span><span style="color:#f1fa8c">roleRef:
</span><span style="color:#f1fa8c">  kind: ClusterRole
</span><span style="color:#f1fa8c">  name: cluster-admin
</span><span style="color:#f1fa8c">  apiGroup: rbac.authorization.k8s.io
</span><span style="color:#f1fa8c">EOF</span>
</code></pre></div><h3 id="配置dashboard-controller">配置dashboard-controller</h3>
<pre><code>20a21
&gt;       serviceAccountName: dashboard
</code></pre><ul>
<li>使用名为 dashboard 的自定义 ServiceAccount</li>
</ul>
<h3 id="配置dashboard-service">配置dashboard-service</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ diff dashboard-service.yaml.orig dashboard-service.yaml
10a11
&gt;   type: NodePort
</code></pre></div><ul>
<li>指定端口类型为 NodePort，这样外界可以通过地址 nodeIP:nodePort 访问 dashboard</li>
</ul>
<h3 id="执行所有定义文件-1">执行所有定义文件</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ <span style="color:#8be9fd;font-style:italic">pwd</span>
/home/ych/k8s-repo/dashboard
$ ls *.yaml
dashboard-controller.yaml  dashboard-rbac.yaml  dashboard-service.yaml
$ kubectl create -f  .
</code></pre></div><h3 id="检查执行结果">检查执行结果</h3>
<p>查看分配的 NodePort</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl get services kubernetes-dashboard -n kube-system
NAME                   TYPE       CLUSTER-IP      EXTERNAL-IP   PORT<span style="color:#ff79c6">(</span>S<span style="color:#ff79c6">)</span>        AGE
kubernetes-dashboard   NodePort   10.254.104.90   &lt;none&gt;        80:31202/TCP   1m
</code></pre></div><ul>
<li>NodePort 31202映射到dashboard pod 80端口；</li>
</ul>
<p>检查 controller</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl get deployment kubernetes-dashboard  -n kube-system
NAME                   DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
kubernetes-dashboard   <span style="color:#bd93f9">1</span>         <span style="color:#bd93f9">1</span>         <span style="color:#bd93f9">1</span>            <span style="color:#bd93f9">1</span>           3m

$ kubectl get pods  -n kube-system | grep dashboard
kubernetes-dashboard-6667f9b4c-4xbpz   1/1       Running   <span style="color:#bd93f9">0</span>          3m
</code></pre></div><h3 id="访问dashboard">访问dashboard</h3>
<ol>
<li>kubernetes-dashboard 服务暴露了 NodePort，可以使用 <code>http://NodeIP:nodePort</code> 地址访问 dashboard</li>
<li>通过 kube-apiserver 访问 dashboard</li>
<li>通过 kubectl proxy 访问 dashboard</li>
</ol>
<p>
  <img src="/img/posts/dashboard.png" alt="dashboard ui">

</p>
<p>由于缺少 Heapster 插件，当前 dashboard 不能展示 Pod、Nodes 的 CPU、内存等 metric 图形</p>
<blockquote>
<p>注意：如果你的后端<code>apiserver</code>是高可用的集群模式的话，那么<code>Dashboard</code>的<code>apiserver-host</code>最好手动指定，不然，当你<code>apiserver</code>某个节点挂了的时候，<code>Dashboard</code>可能不能正常访问，如下配置</p>
</blockquote>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#ff79c6">image</span>: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.7.1
<span style="color:#ff79c6">ports</span>:
- <span style="color:#ff79c6">containerPort</span>: <span style="color:#bd93f9">9090</span>
  <span style="color:#ff79c6">protocol</span>: TCP
<span style="color:#ff79c6">args</span>:
  - --apiserver-host=http://&lt;api_server_ha_addr&gt;:8080
</code></pre></div><h2 id="11-部署heapster-插件a-idheapstera">11. 部署Heapster 插件<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<p>到<a href="https://github.com/kubernetes/heapster/releases">heapster release</a> 页面下载最新版的heapster</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ wget https://github.com/kubernetes/heapster/archive/v1.4.3.tar.gz
$ tar -xzvf v1.4.3.tar.gz
</code></pre></div><p>部署相关文件目录：<code>/home/ych/k8s-repo/heapster-1.4.3/deploy/kube-config</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ ls influxdb/ <span style="color:#ff79c6">&amp;&amp;</span> ls rbac/
grafana.yaml  heapster.yaml  influxdb.yaml
heapster-rbac.yaml
</code></pre></div><p>为方便测试访问，将<code>grafana.yaml</code>下面的服务类型设置为<code>type=NodePort</code></p>
<h3 id="执行所有文件">执行所有文件</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl create -f rbac/heapster-rbac.yaml
clusterrolebinding <span style="color:#f1fa8c">&#34;heapster&#34;</span> created
$ kubectl create -f influxdb
deployment <span style="color:#f1fa8c">&#34;monitoring-grafana&#34;</span> created
service <span style="color:#f1fa8c">&#34;monitoring-grafana&#34;</span> created
serviceaccount <span style="color:#f1fa8c">&#34;heapster&#34;</span> created
deployment <span style="color:#f1fa8c">&#34;heapster&#34;</span> created
service <span style="color:#f1fa8c">&#34;heapster&#34;</span> created
deployment <span style="color:#f1fa8c">&#34;monitoring-influxdb&#34;</span> created
service <span style="color:#f1fa8c">&#34;monitoring-influxdb&#34;</span> created
</code></pre></div><h3 id="检查执行结果-1">检查执行结果</h3>
<p>检查 Deployment</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl get deployments -n kube-system | grep -E <span style="color:#f1fa8c">&#39;heapster|monitoring&#39;</span>
heapster               <span style="color:#bd93f9">1</span>         <span style="color:#bd93f9">1</span>         <span style="color:#bd93f9">1</span>            <span style="color:#bd93f9">1</span>           2m
monitoring-grafana     <span style="color:#bd93f9">1</span>         <span style="color:#bd93f9">1</span>         <span style="color:#bd93f9">1</span>            <span style="color:#bd93f9">0</span>           2m
monitoring-influxdb    <span style="color:#bd93f9">1</span>         <span style="color:#bd93f9">1</span>         <span style="color:#bd93f9">1</span>            <span style="color:#bd93f9">1</span>           2m
</code></pre></div><p>检查 Pods</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl get pods -n kube-system | grep -E <span style="color:#f1fa8c">&#39;heapster|monitoring&#39;</span>
heapster-7cf895f48f-p98tk              1/1       Running            <span style="color:#bd93f9">0</span>          2m
monitoring-grafana-c9d5cd98d-gb9xn     0/1       CrashLoopBackOff   <span style="color:#bd93f9">4</span>          2m
monitoring-influxdb-67f8d587dd-zqj6p   1/1       Running            <span style="color:#bd93f9">0</span>          2m
</code></pre></div><p>我们可以看到<code>monitoring-grafana</code>的POD 是没有执行成功的，通过查看日志可以看到下面的错误信息：</p>
<blockquote>
<p>Failed to parse /etc/grafana/grafana.ini, open /etc/grafana/grafana.ini: no such file or directory</p>
</blockquote>
<p>要解决这个问题(<a href="https://github.com/kubernetes/heapster/issues/1709">heapster issues</a>)我们需要将grafana 的镜像版本更改成：<code>gcr.io/google_containers/heapster-grafana-amd64:v4.0.2</code>，然后重新执行，即可正常。</p>
<h3 id="访问-grafana">访问 grafana</h3>
<p>上面我们修改grafana 的Service 为NodePort 类型：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl get svc -n kube-system
NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT<span style="color:#ff79c6">(</span>S<span style="color:#ff79c6">)</span>         AGE
monitoring-grafana     NodePort    10.254.34.89    &lt;none&gt;        80:30191/TCP    28m
</code></pre></div><p>则我们就可以通过任意一个节点加上上面的30191端口就可以访问grafana 了。</p>
<p>
  <img src="/img/posts/WX20171110-141935.png" alt="grafana ui">

</p>
<p>heapster 正确安装后，我们便可以回去看我们的dashboard 是否有图表出现了：</p>
<p>
  <img src="/img/posts/WX20171110-105351.png" alt="dashboard">

</p>
<h2 id="12-安装ingressa-idingressa">12. 安装Ingress<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<p><code>Ingress</code>其实就是从<code>kuberenets</code>集群外部访问集群的一个入口，将外部的请求转发到集群内不同的Service 上，其实就相当于nginx、apache 等负载均衡代理服务器，再加上一个规则定义，路由信息的刷新需要靠<code>Ingress controller</code>来提供</p>
<p><code>Ingress controller</code>可以理解为一个监听器，通过不断地与<code>kube-apiserver</code>打交道，实时的感知后端service、pod 等的变化，当得到这些变化信息后，<code>Ingress controller</code>再结合<code>Ingress</code>的配置，更新反向代理负载均衡器，达到服务发现的作用。其实这点和服务发现工具<code>consul</code>的<code>consul-template</code>非常类似。</p>
<h3 id="部署traefik">部署traefik</h3>
<p><a href="https://traefik.io/">Traefik</a>是一款开源的反向代理与负载均衡工具。它最大的优点是能够与常见的微服务系统直接整合，可以实现自动化动态配置。目前支持<strong>Docker、Swarm、Mesos/Marathon、 Mesos、Kubernetes、Consul、Etcd、Zookeeper、BoltDB、Rest API</strong>等等后端模型。</p>
<p>
  <img src="/img/posts/traefik-architecture.png" alt="traefik">

</p>
<h4 id="创建rbac">创建rbac</h4>
<p>创建文件：<code>ingress-rbac.yaml</code>，用于<code>service account</code>验证</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#ff79c6">apiVersion</span>: v1
<span style="color:#ff79c6">kind</span>: ServiceAccount
<span style="color:#ff79c6">metadata</span>:
  <span style="color:#ff79c6">name</span>: ingress
  <span style="color:#ff79c6">namespace</span>: kube-system
---
<span style="color:#ff79c6">kind</span>: ClusterRoleBinding
<span style="color:#ff79c6">apiVersion</span>: rbac.authorization.k8s.io/v1beta1
<span style="color:#ff79c6">metadata</span>:
  <span style="color:#ff79c6">name</span>: ingress
<span style="color:#ff79c6">subjects</span>:
  - <span style="color:#ff79c6">kind</span>: ServiceAccount
    <span style="color:#ff79c6">name</span>: ingress
    <span style="color:#ff79c6">namespace</span>: kube-system
<span style="color:#ff79c6">roleRef</span>:
  <span style="color:#ff79c6">kind</span>: ClusterRole
  <span style="color:#ff79c6">name</span>: cluster-admin
  <span style="color:#ff79c6">apiGroup</span>: rbac.authorization.k8s.io
</code></pre></div><h4 id="daemonset-形式部署traefik">DaemonSet 形式部署traefik</h4>
<p>创建文件：<code>traefik-daemonset.yaml</code>，为保证traefik 总能提供服务，在每个节点上都部署一个traefik，所以这里使用<code>DaemonSet</code> 的形式</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#ff79c6">kind</span>: ConfigMap
<span style="color:#ff79c6">apiVersion</span>: v1
<span style="color:#ff79c6">metadata</span>:
  <span style="color:#ff79c6">name</span>: traefik-conf
  <span style="color:#ff79c6">namespace</span>: kube-system
<span style="color:#ff79c6">data</span>:
  <span style="color:#ff79c6">traefik-config</span>: |-<span style="color:#f1fa8c">
</span><span style="color:#f1fa8c">    defaultEntryPoints = [&#34;http&#34;,&#34;https&#34;]
</span><span style="color:#f1fa8c">    [entryPoints]
</span><span style="color:#f1fa8c">      [entryPoints.http]
</span><span style="color:#f1fa8c">      address = &#34;:80&#34;
</span><span style="color:#f1fa8c">        [entryPoints.http.redirect]
</span><span style="color:#f1fa8c">          entryPoint = &#34;https&#34;
</span><span style="color:#f1fa8c">      [entryPoints.https]
</span><span style="color:#f1fa8c">      address = &#34;:443&#34;
</span><span style="color:#f1fa8c">        [entryPoints.https.tls]
</span><span style="color:#f1fa8c">          [[entryPoints.https.tls.certificates]]
</span><span style="color:#f1fa8c">          CertFile = &#34;/ssl/ssl.crt&#34;
</span><span style="color:#f1fa8c">          KeyFile = &#34;/ssl/ssl.key&#34;</span>    

---
<span style="color:#ff79c6">kind</span>: DaemonSet
<span style="color:#ff79c6">apiVersion</span>: extensions/v1beta1
<span style="color:#ff79c6">metadata</span>:
  <span style="color:#ff79c6">name</span>: traefik-ingress
  <span style="color:#ff79c6">namespace</span>: kube-system
  <span style="color:#ff79c6">labels</span>:
    <span style="color:#ff79c6">k8s-app</span>: traefik-ingress
<span style="color:#ff79c6">spec</span>:
  <span style="color:#ff79c6">template</span>:
    <span style="color:#ff79c6">metadata</span>:
      <span style="color:#ff79c6">labels</span>:
        <span style="color:#ff79c6">k8s-app</span>: traefik-ingress
        <span style="color:#ff79c6">name</span>: traefik-ingress
    <span style="color:#ff79c6">spec</span>:
      <span style="color:#ff79c6">terminationGracePeriodSeconds</span>: <span style="color:#bd93f9">60</span>
      <span style="color:#ff79c6">restartPolicy</span>: Always
      <span style="color:#ff79c6">serviceAccountName</span>: ingress
      <span style="color:#ff79c6">containers</span>:
      - <span style="color:#ff79c6">image</span>: traefik:latest
        <span style="color:#ff79c6">name</span>: traefik-ingress
        <span style="color:#ff79c6">ports</span>:
        - <span style="color:#ff79c6">name</span>: http
          <span style="color:#ff79c6">containerPort</span>: <span style="color:#bd93f9">80</span>
          <span style="color:#ff79c6">hostPort</span>: <span style="color:#bd93f9">80</span>
        - <span style="color:#ff79c6">name</span>: https
          <span style="color:#ff79c6">containerPort</span>: <span style="color:#bd93f9">443</span>
          <span style="color:#ff79c6">hostPort</span>: <span style="color:#bd93f9">443</span>
        - <span style="color:#ff79c6">name</span>: admin
          <span style="color:#ff79c6">containerPort</span>: <span style="color:#bd93f9">8080</span>
        <span style="color:#ff79c6">args</span>:
        - --configFile=/etc/traefik/traefik.toml
        - -d
        - --web
        - --kubernetes
        - --logLevel=DEBUG
        <span style="color:#ff79c6">volumeMounts</span>:
        - <span style="color:#ff79c6">name</span>: traefik-config-volume
          <span style="color:#ff79c6">mountPath</span>: /etc/traefik
        - <span style="color:#ff79c6">name</span>: traefik-ssl-volume
          <span style="color:#ff79c6">mountPath</span>: /ssl
      <span style="color:#ff79c6">volumes</span>:
      - <span style="color:#ff79c6">name</span>: traefik-config-volume
        <span style="color:#ff79c6">configMap</span>:
          <span style="color:#ff79c6">name</span>: traefik-conf
          <span style="color:#ff79c6">items</span>:
          - <span style="color:#ff79c6">key</span>: traefik-config
            <span style="color:#ff79c6">path</span>: traefik.toml
      - <span style="color:#ff79c6">name</span>: traefik-ssl-volume
        <span style="color:#ff79c6">secret</span>:
          <span style="color:#ff79c6">secretName</span>: traefik-ssl
</code></pre></div><p>注意上面的yaml 文件中我们添加了一个名为<code>traefik-conf</code>的<code>ConfigMap</code>，该配置是用来将http 请求强制跳转成https，并指定https 所需CA 文件地址，这里我们使用<code>secret</code>的形式来指定CA 文件的路径：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ ls
ssl.crt     ssl.key
$ kubectl create secret generic traefik-ssl --from-file<span style="color:#ff79c6">=</span>ssl.crt --from-file<span style="color:#ff79c6">=</span>ssl.key --namespace<span style="color:#ff79c6">=</span>kube-system
secret <span style="color:#f1fa8c">&#34;traefik-ssl&#34;</span> created
</code></pre></div><h4 id="创建ingress">创建ingress</h4>
<p>创建文件：<code>traefik-ingress.yaml</code>，现在可以通过创建<code>ingress</code>文件来定义请求规则了，根据自己集群中的service 自己修改相应的<code>serviceName</code> 和<code>servicePort</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#ff79c6">apiVersion</span>: extensions/v1beta1
<span style="color:#ff79c6">kind</span>: Ingress
<span style="color:#ff79c6">metadata</span>:
  <span style="color:#ff79c6">name</span>: traefik-ingress
<span style="color:#ff79c6">spec</span>:
  <span style="color:#ff79c6">rules</span>:
  - <span style="color:#ff79c6">host</span>: traefik.nginx.io
    <span style="color:#ff79c6">http</span>:
      <span style="color:#ff79c6">paths</span>:
      - <span style="color:#ff79c6">path</span>: /
        <span style="color:#ff79c6">backend</span>:
          <span style="color:#ff79c6">serviceName</span>: my-nginx
          <span style="color:#ff79c6">servicePort</span>: <span style="color:#bd93f9">80</span>
</code></pre></div><p>执行创建命令：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl create -f ingress-rbac.yaml
serviceaccount <span style="color:#f1fa8c">&#34;ingress&#34;</span> created
clusterrolebinding <span style="color:#f1fa8c">&#34;ingress&#34;</span> created
$ kubectl create -f traefik-daemonset.yaml
configmap <span style="color:#f1fa8c">&#34;traefik-conf&#34;</span> created
daemonset <span style="color:#f1fa8c">&#34;traefik-ingress&#34;</span> created
$ kubectl create -f traefik-ingress.yaml
ingress <span style="color:#f1fa8c">&#34;traefik-ingress&#34;</span> created
</code></pre></div><h4 id="traefik-ui">Traefik UI</h4>
<p>创建文件：<code>traefik-ui.yaml</code>，</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#ff79c6">apiVersion</span>: v1
<span style="color:#ff79c6">kind</span>: Service
<span style="color:#ff79c6">metadata</span>:
  <span style="color:#ff79c6">name</span>: traefik-ui
  <span style="color:#ff79c6">namespace</span>: kube-system
<span style="color:#ff79c6">spec</span>:
  <span style="color:#ff79c6">selector</span>:
    <span style="color:#ff79c6">k8s-app</span>: traefik-ingress
  <span style="color:#ff79c6">ports</span>:
  - <span style="color:#ff79c6">name</span>: web
    <span style="color:#ff79c6">port</span>: <span style="color:#bd93f9">80</span>
    <span style="color:#ff79c6">targetPort</span>: <span style="color:#bd93f9">8080</span>
---
<span style="color:#ff79c6">apiVersion</span>: extensions/v1beta1
<span style="color:#ff79c6">kind</span>: Ingress
<span style="color:#ff79c6">metadata</span>:
  <span style="color:#ff79c6">name</span>: traefik-ui
  <span style="color:#ff79c6">namespace</span>: kube-system
<span style="color:#ff79c6">spec</span>:
  <span style="color:#ff79c6">rules</span>:
  - <span style="color:#ff79c6">host</span>: traefik-ui.local
    <span style="color:#ff79c6">http</span>:
      <span style="color:#ff79c6">paths</span>:
      - <span style="color:#ff79c6">path</span>: /
        <span style="color:#ff79c6">backend</span>:
          <span style="color:#ff79c6">serviceName</span>: traefik-ui
          <span style="color:#ff79c6">servicePort</span>: web
</code></pre></div><h3 id="测试">测试</h3>
<p>部署完成后，在本地<code>/etc/hosts</code>添加一条配置：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#6272a4"># 将下面的xx.xx.xx.xx替换成任意节点IP</span>
xx.xx.xx.xx master03 traefik.nginx.io traefik-ui.local
</code></pre></div><p>配置完成后，在本地访问：<code>traefik-ui.local</code>，则可以访问到<code>traefik</code>的<code>dashboard</code>页面：</p>
<p>
  <img src="/img/posts/WX20171110-140151.png" alt="traefik dashboard">

</p>
<p>同样的可以访问<code>traefik.nginx.io</code>，得到正确的结果页面：</p>
<p>
  <img src="/img/posts/WX20171110-140306.png" alt="WX20171110-140306">

</p>
<p>上面配置完成后，就可以将我们的所有节点加入到一个<code>SLB</code>中，然后配置相应的域名解析到<code>SLB</code>即可。</p>
<h2 id="13-日志收集a-idlog-collecta">13. 日志收集<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<p>参考文章<a href="/post/kubernetes-logs-collect/">kubernetes 日志收集方案</a></p>
<h2 id="14-私有仓库harbor-搭建a-idharbora">14. 私有仓库harbor 搭建<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<p>参考文章<a href="/post/install-docker-registry-harbor-in-kubernetes/">在kubernetes 上搭建docker 私有仓库Harbor</a></p>
<h2 id="15-问题汇总a-idquestiona">15. 问题汇总<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<h4 id="151-dashboard无法显示监控图">15.1 dashboard无法显示监控图</h4>
<p>dashboard 和heapster influxdb都部署完成后 dashboard依旧无法显示监控图 通过排查 heapster log有超时错误</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl logs -f pods/heapster-2882613285-58d9r -n kube-system

E0630 17:23:47.339987 <span style="color:#bd93f9">1</span> reflector.go:203<span style="color:#ff79c6">]</span> k8s.io/heapster/metrics/sources/kubelet/kubelet.go:342: Failed to list *api.Node: Get http://kubernetes.default/api/v1/nodes?resourceVersion<span style="color:#ff79c6">=</span>0: dial tcp: i/o timeout E0630 17:23:47.340274 <span style="color:#bd93f9">1</span> reflector.go:203<span style="color:#ff79c6">]</span> k8s.io/heapster/metrics/heapster.go:319: Failed to list *api.Pod: Get http://kubernetes.default/api/v1/pods?resourceVersion<span style="color:#ff79c6">=</span>0: dial tcp: i/o timeout E0630 17:23:47.340498 <span style="color:#bd93f9">1</span> reflector.go:203<span style="color:#ff79c6">]</span> k8s.io/heapster/metrics/processors/namespace_based_enricher.go:84: Failed to list *api.Namespace: Get http://kubernetes.default/api/v1/namespaces?resourceVersion<span style="color:#ff79c6">=</span>0: dial tcp: lookup kubernetes.default on 10.254.0.2:53: dial udp 10.254.0.2:53: i/o timeout E0630 17:23:47.340563 <span style="color:#bd93f9">1</span> reflector.go:203<span style="color:#ff79c6">]</span> k8s.io/heapster/metrics/heapster.go:327: Failed to list *api.Node: Get http://kubernetes.default/api/v1/nodes?resourceVersion<span style="color:#ff79c6">=</span>0: dial tcp: lookup kubernetes.default on 10.254.0.2:53: dial udp 10.254.0.2:53: i/o timeout E0630 17:23:47.340623 <span style="color:#bd93f9">1</span> reflector.go:203<span style="color:#ff79c6">]</span> k8s.io/heapster/metrics/processors/node_autoscaling_enricher.go💯 Failed to list *api.Node: Get http://kubernetes.default/api/v1/nodes?resourceVersion<span style="color:#ff79c6">=</span>0: dial tcp: lookup kubernetes.default on 10.254.0.2:53: dial udp 10.254.0.2:53: i/o timeout E0630 17:23:55.014414 <span style="color:#bd93f9">1</span> influxdb.go:150<span style="color:#ff79c6">]</span> Failed to create infuxdb: failed to ping InfluxDB server at <span style="color:#f1fa8c">&#34;monitoring-influxdb:8086&#34;</span> - Get http://monitoring-influxdb:8086/ping: dial tcp: lookup monitoring-influxdb on 10.254.0.2:53: <span style="color:#8be9fd;font-style:italic">read</span> udp 172.30.45.4:48955-&gt;10.254.0.2:53: i/o timeout<span style="color:#f1fa8c">`</span>
</code></pre></div><p>我是docker的systemd Unit文件忘记添加</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#8be9fd;font-style:italic">ExecStart</span><span style="color:#ff79c6">=</span>/root/local/bin/dockerd --log-level<span style="color:#ff79c6">=</span>error <span style="color:#8be9fd;font-style:italic">$DOCKER_NETWORK_OPTIONS</span>
</code></pre></div><p>后边的<code>$DOCKER_NETWORK_OPTIONS</code>，导致<code>docker0</code>的网段跟<code>flannel.1</code>不一致。</p>
<h4 id="152-kube-proxy报错kube-proxy2241-e0502-155513889842-2241-conntrackgo42-conntrack-returned-error-error-looking-for-path-of-conntrack-exec-conntrack-executable-file-not-found-in-path">15.2 kube-proxy报错kube-proxy[2241]: E0502 15:55:13.889842 2241 conntrack.go:42] conntrack returned error: error looking for path of conntrack: exec: &ldquo;conntrack&rdquo;: executable file not found in $PATH</h4>
<p><strong>导致现象</strong>：<code>kubedns</code>启动成功，运行正常，但是service 之间无法解析，<code>kubernetes</code>中的<code>DNS</code>解析异常</p>
<p><strong>解决方法</strong>：<code>CentOS</code>中安装<code>conntrack-tools</code>包后重启kubernetes 集群即可。</p>
<h4 id="153-unable-to-access-kubernetes-services-no-route-to-host">15.3 Unable to access kubernetes services: no route to host</h4>
<p><strong>导致现象</strong>: 在POD 内访问集群的某个服务的时候出现<code>no route to host</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ curl my-nginx.nx.svc.cluster.local
curl: <span style="color:#ff79c6">(</span>7<span style="color:#ff79c6">)</span> Failed connect to my-nginx.nx.svc.cluster.local:80; No route to host
</code></pre></div><p><strong>解决方法</strong>：清除所有的防火墙规则，然后重启docker 服务</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ iptables --flush <span style="color:#ff79c6">&amp;&amp;</span> iptables -tnat --flush
$ systemctl restart docker
</code></pre></div><h4 id="154-使用nodeport-类型的服务只能在pod-所在节点进行访问">15.4 使用NodePort 类型的服务，只能在POD 所在节点进行访问</h4>
<p><strong>导致现象</strong>:  使用<code>NodePort</code> 类型的服务，只能在POD 所在节点进行访问，其他节点通过NodePort 不能正常访问</p>
<p><strong>解决方法</strong>:  <code>kube-proxy</code> 默认使用的是<code>proxy_model</code>就是<code>iptables</code>，正常情况下是所有节点都可以通过NodePort 进行访问的，我这里将阿里云的安全组限制全部去掉即可，然后根据需要进行添加安全限制。</p>
<h2 id="参考资料a-idlinka">参考资料<!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<ul>
<li><a href="https://github.com/opsnull/follow-me-install-kubernetes-cluster">和我一步步部署 kubernetes 集群</a></li>
<li><a href="http://www.rfyy.net/archives/1504.html">keepalived 配置</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/issues">kubernetes issue</a></li>
<li><a href="https://github.com/kubernetes/heapster/issues">kubernetes heapster issue</a></li>
</ul>
<p><a href="https://www.haimaxy.com/course/pjrqxm/?utm_source=blog">基于1.9版本手动搭建高可用Kubernetes集群的视频教程</a>，对视频感兴趣的同学可以观看视频：
<a href="https://www.haimaxy.com/course/pjrqxm/?utm_source=blog">
  <img src="/img/posts/k8s-install-pay-course.jpeg" alt="视频教程">

</a></p>

                
                
<div class="entry-shang text-center">
    
	    <p> 「如果这篇文章对你有用,请随意打赏」</p>
	
	<button class="zs show-zs btn btn-bred">赞赏支持</button>
</div>
<div class="zs-modal-bg"></div>
<div class="zs-modal-box">
	<div class="zs-modal-head">
		<button type="button" class="close">×</button>
		<span class="author"><a href="https://qnxr.xyz"><img src="/img/favicon.png" />青年夏日IT</a></span>
        
	        <p class="tip"><i></i><span>如果这篇文章对你有用,请随意打赏</span></p>
		
 
	</div>
	<div class="zs-modal-body">
		<div class="zs-modal-btns">
			<button class="btn btn-blink" data-num="2">2元</button>
			<button class="btn btn-blink" data-num="5">5元</button>
			<button class="btn btn-blink" data-num="10">10元</button>
			<button class="btn btn-blink" data-num="50">50元</button>
			<button class="btn btn-blink" data-num="100">100元</button>
			<button class="btn btn-blink" data-num="1">任意金额</button>
		</div>
		<div class="zs-modal-pay">
			<button class="btn btn-bred" id="pay-text">2元</button>
			<p>使用<span id="pay-type">微信</span>扫描二维码完成支付</p>
			<img src="/img/reward/wechat-2.png"  id="pay-image"/>
		</div>
	</div>
	<div class="zs-modal-footer">
		<label><input type="radio" name="zs-type" value="wechat" class="zs-type" checked="checked"><span ><span class="zs-wechat"><img src="/img/reward/wechat-btn.png"/></span></label>
		<label><input type="radio" name="zs-type" value="alipay" class="zs-type" class="zs-alipay"><img src="/img/reward/alipay-btn.png"/></span></label>
	</div>
</div>
<script type="text/javascript" src="/js/reward.js"></script>

                

                <hr>
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/post/make-https-blog/" data-toggle="tooltip" data-placement="top" title="给博客加上HTTPS">&larr;
                            Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2017/11/07/istio-traffic-shifting/" data-toggle="tooltip" data-placement="top" title="使用Istio实现应用流量转移">Next
                            Post &rarr;</a>
                    </li>
                    
                </ul>

                
<div id="disqus-comment"></div>



            </div>
            
            <div class="
                col-lg-11 col-lg-offset-1
                col-md-10 col-md-offset-1
                sidebar-container">

                
                
                <section>
                    <hr class="hidden-sm hidden-xs">
                    <h5><a href="/tags/">标签</a></h5>
                    <div class="tags">
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/affinity" title="affinity">
                            affinity
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/alertmanager" title="alertmanager">
                            alertmanager
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/argo" title="argo">
                            argo
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/cd" title="cd">
                            cd
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/ci" title="ci">
                            ci
                        </a>
                        
                        
                        
                        <a href="/tags/ci/cd" title="ci/cd">
                            ci/cd
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/configmap" title="configmap">
                            configmap
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/coredns" title="coredns">
                            coredns
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/dashboard" title="dashboard">
                            dashboard
                        </a>
                        
                        
                        
                        <a href="/tags/deployment" title="deployment">
                            deployment
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/devops" title="devops">
                            devops
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/django" title="django">
                            django
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/docker" title="docker">
                            docker
                        </a>
                        
                        
                        
                        <a href="/tags/dockerfile" title="dockerfile">
                            dockerfile
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/drone" title="drone">
                            drone
                        </a>
                        
                        
                        
                        <a href="/tags/efk" title="efk">
                            efk
                        </a>
                        
                        
                        
                        <a href="/tags/elastic" title="elastic">
                            elastic
                        </a>
                        
                        
                        
                        <a href="/tags/elasticsearch" title="elasticsearch">
                            elasticsearch
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/envoy" title="envoy">
                            envoy
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/flask" title="flask">
                            flask
                        </a>
                        
                        
                        
                        <a href="/tags/fluentd" title="fluentd">
                            fluentd
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/github" title="github">
                            github
                        </a>
                        
                        
                        
                        <a href="/tags/gitlab" title="gitlab">
                            gitlab
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/gitops" title="gitops">
                            gitops
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/goland" title="goland">
                            goland
                        </a>
                        
                        
                        
                        <a href="/tags/golang" title="golang">
                            golang
                        </a>
                        
                        
                        
                        <a href="/tags/grafana" title="grafana">
                            grafana
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/haproxy" title="haproxy">
                            haproxy
                        </a>
                        
                        
                        
                        <a href="/tags/harbor" title="harbor">
                            harbor
                        </a>
                        
                        
                        
                        <a href="/tags/helm" title="helm">
                            helm
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/https" title="https">
                            https
                        </a>
                        
                        
                        
                        <a href="/tags/hugo" title="hugo">
                            hugo
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/ingress" title="ingress">
                            ingress
                        </a>
                        
                        
                        
                        <a href="/tags/ingress-nginx" title="ingress-nginx">
                            ingress-nginx
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/iptables" title="iptables">
                            iptables
                        </a>
                        
                        
                        
                        <a href="/tags/ipvs" title="ipvs">
                            ipvs
                        </a>
                        
                        
                        
                        <a href="/tags/istio" title="istio">
                            istio
                        </a>
                        
                        
                        
                        <a href="/tags/java" title="java">
                            java
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/jenkins" title="jenkins">
                            jenkins
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/k8s" title="k8s">
                            k8s
                        </a>
                        
                        
                        
                        <a href="/tags/k8s%E6%8A%80%E6%9C%AF%E5%9C%88" title="k8s技术圈">
                            k8s技术圈
                        </a>
                        
                        
                        
                        <a href="/tags/kafka" title="kafka">
                            kafka
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/kibana" title="kibana">
                            kibana
                        </a>
                        
                        
                        
                        <a href="/tags/kind" title="kind">
                            kind
                        </a>
                        
                        
                        
                        <a href="/tags/kong" title="kong">
                            kong
                        </a>
                        
                        
                        
                        <a href="/tags/kubeadm" title="kubeadm">
                            kubeadm
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/kubelet" title="kubelet">
                            kubelet
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/kubernetes" title="kubernetes">
                            kubernetes
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/kustomize" title="kustomize">
                            kustomize
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/loki" title="loki">
                            loki
                        </a>
                        
                        
                        
                        <a href="/tags/mac" title="mac">
                            mac
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/microservice" title="microservice">
                            microservice
                        </a>
                        
                        
                        
                        <a href="/tags/monitor" title="monitor">
                            monitor
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/netfilter" title="netfilter">
                            netfilter
                        </a>
                        
                        
                        
                        <a href="/tags/nfs" title="nfs">
                            nfs
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/nginx" title="nginx">
                            nginx
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/operator" title="operator">
                            operator
                        </a>
                        
                        
                        
                        <a href="/tags/ops" title="ops">
                            ops
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/pipeline" title="pipeline">
                            pipeline
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/pod" title="pod">
                            pod
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/prometheus" title="prometheus">
                            prometheus
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/pv" title="pv">
                            pv
                        </a>
                        
                        
                        
                        <a href="/tags/pvc" title="pvc">
                            pvc
                        </a>
                        
                        
                        
                        <a href="/tags/pycharm" title="pycharm">
                            pycharm
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/python" title="python">
                            python
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/rbac" title="rbac">
                            rbac
                        </a>
                        
                        
                        
                        <a href="/tags/react" title="react">
                            react
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/scheduler" title="scheduler">
                            scheduler
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/security" title="security">
                            security
                        </a>
                        
                        
                        
                        <a href="/tags/service" title="service">
                            service
                        </a>
                        
                        
                        
                        <a href="/tags/service-api" title="service-api">
                            service-api
                        </a>
                        
                        
                        
                        <a href="/tags/service-mesh" title="service-mesh">
                            service-mesh
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/slave" title="slave">
                            slave
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/storageclass" title="storageclass">
                            storageclass
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/tcpdump" title="tcpdump">
                            tcpdump
                        </a>
                        
                        
                        
                        <a href="/tags/tdd" title="tdd">
                            tdd
                        </a>
                        
                        
                        
                        <a href="/tags/tekton" title="tekton">
                            tekton
                        </a>
                        
                        
                        
                        <a href="/tags/tips" title="tips">
                            tips
                        </a>
                        
                        
                        
                        <a href="/tags/traefik" title="traefik">
                            traefik
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/vault" title="vault">
                            vault
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/vscode" title="vscode">
                            vscode
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/webpack" title="webpack">
                            webpack
                        </a>
                        
                        
                        
                        <a href="/tags/websocket" title="websocket">
                            websocket
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/wsl" title="wsl">
                            wsl
                        </a>
                        
                        
                        
                        <a href="/tags/yaml" title="yaml">
                            yaml
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1" title="微服务">
                            微服务
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83" title="知识星球">
                            知识星球
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E8%AF%BE%E7%A8%8B" title="课程">
                            课程
                        </a>
                        
                        
                        
                        <a href="/tags/%E8%B0%83%E5%BA%A6" title="调度">
                            调度
                        </a>
                        
                        
                        
                        <a href="/tags/%E9%98%BF%E9%87%8C%E4%BA%91" title="阿里云">
                            阿里云
                        </a>
                        
                        
                        
                        
                        
                        
                    </div>
                </section>
                

                
                
            </div>
        </div>
    </div>
</article>




<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                   
                    
                    <li>
                        <a href="mailto:1290851757@qq.com">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    

                    
                    <li>
                        <a href="img/wechat_qrcode.jpg">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    

                    
                    <li>
                        <a target="_blank" href="img/wechat_qrcode.jpg">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-facebook fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    

		    
                    
                    
                    <li>
                        <a target="_blank" href="https://github.com/xiaobingchan">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    
                    
                    
                    
                    <li>
                        <a target="_blank" href="img/alipay.jpg">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    
                    
                    
                    
                    
                    
            
            
            
                </ul>
		<p class="copyright text-muted">
                    Copyright &copy; 青年夏日IT 2021
                    <br>
                    <a href="https://themes.gohugo.io/hugo-theme-cleanwhite"></a><a href="http://qnxr.xyz">青年夏日IT版权所有</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=xiaobingchan&repo=xiaobingchan.github.io&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>




<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>






<script>
    
    if($('#tag_cloud').length !== 0){
        async("/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>


<script>
    async("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>






<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-150373352-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



</body>
</html>
